{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification Tutorial: P3 Visual Oddball Task\n",
    "\n",
    "This tutorial demonstrates using the *EEGDash* library with PyTorch to classify EEG responses from a visual P3 oddball paradigm.\n",
    "\n",
    "1. **Data Description**: Dataset contains EEG recordings during a visual oddball task where:\n",
    "\n",
    "   - Letters A, B, C, D, and E were presented randomly (p = .2 for each)\n",
    "   - One letter was designated as target (oddball) for each block\n",
    "   - Other letters served as non-targets (standard)\n",
    "   - Participants responded whether each letter was target or non-target\n",
    "\n",
    "2. **Data Preprocessing**: \n",
    "\n",
    "   - Applies bandpass filtering (1-55 Hz)\n",
    "   - Selects first 30 EEG channels\n",
    "   - Downsamples from 1024Hz to 256Hz\n",
    "   - Creates event-based windows (0.1s to 0.6s post-stimulus)\n",
    "\n",
    "3. **Dataset Preparation**: \n",
    "\n",
    "   - Maps events into two classes:\n",
    "     * oddball: events where block target matches trial stimulus (11,22,33,44,55)\n",
    "     * standard: events where block target differs from trial stimulus\n",
    "     * Note: Response events (201, 202) are excluded\n",
    "   - Splits into training (80%) and test (20%) sets\n",
    "   - Creates PyTorch DataLoaders\n",
    "\n",
    "4. **Model**: \n",
    "\n",
    "   - ShallowFBCSPNet architecture\n",
    "   - 30 input channels, 2 output classes\n",
    "   - 128-sample input windows (0.5s at 256Hz)\n",
    "\n",
    "5. **Training**: \n",
    "\n",
    "   - Adamax optimizer with learning rate decay\n",
    "   - 5 training epochs\n",
    "   - Reports accuracy on train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval Using EEGDash\n",
    "\n",
    "The P3 Visual Oddball dataset is stored in BIDS format. We use EEGDash to load and manage the data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected files from subject-001:\n",
      "1. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\P3 Raw Data BIDS-Compatible\\sub-001\\eeg\\sub-001_task-P3_eeg.set\n"
     ]
    }
   ],
   "source": [
    "from eegdash.data_utils import EEGBIDSDataset\n",
    "\n",
    "dataset = EEGBIDSDataset(\n",
    "    data_dir=\"d:/Users/vivian/Desktop/UCSD/EEG/P3 Raw Data BIDS-Compatible\",\n",
    "    dataset=\"P3 Raw Data BIDS-Compatible\",\n",
    ")\n",
    "\n",
    "all_files = dataset.get_files()\n",
    "\n",
    "# Select files from subject-001\n",
    "subject_files = [f for f in all_files if \"sub-001\" in f]\n",
    "print(\"\\nSelected files from subject-001:\")\n",
    "for i, file in enumerate(subject_files):\n",
    "    print(f\"{i + 1}. {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Using Braindecode\n",
    "\n",
    "[Braindecode](https://braindecode.org/) provides powerful tools for EEG data preprocessing and analysis. Our implementation processes EEG data with these key steps:\n",
    "\n",
    "1. **Channel Selection & Signal Processing**:\n",
    "   - Selecting first 30 EEG channels\n",
    "   - Bandpass filtering between 1-55 Hz\n",
    "   - Downsampling from 1024Hz to 256Hz\n",
    "\n",
    "2. **Event Processing**:\n",
    "   - Reading events from events.tsv file:\n",
    "     * Block A: 11=oddball, 12-15=standard\n",
    "     * Block B: 22=oddball, 21,23-25=standard\n",
    "     * Block C: 33=oddball, 31-32,34-35=standard\n",
    "     * Block D: 44=oddball, 41-43,45=standard\n",
    "     * Block E: 55=oddball, 51-54=standard\n",
    "     * Response events (201, 202) are excluded\n",
    "\n",
    "3. **Window Creation**:\n",
    "\n",
    "   - Window duration: 1s\n",
    "   - Efficient memory usage with on-demand loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Event distribution:\n",
      "Oddball events (11,22,33,44,55): 20\n",
      "Standard events: 382\n",
      "\n",
      "All files processed, total number of windows: 402\n",
      "Window shape: (30, 128)\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import (\n",
    "    preprocess,\n",
    "    Preprocessor,\n",
    "    create_windows_from_events,\n",
    ")\n",
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "import warnings\n",
    "import logging\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from mne.io import read_raw_eeglab\n",
    "import pandas as pd\n",
    "\n",
    "mne.set_log_level(\"ERROR\")\n",
    "logging.getLogger(\"joblib\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class P3OddballPreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    A preprocessor that combines channel selection, filtering, and event mapping\n",
    "    for P3 oddball paradigm EEG data.\n",
    "\n",
    "    Maps events based on block target and trial stimulus:\n",
    "        Block A: 11=oddball, 12-15=standard\n",
    "        Block B: 22=oddball, 21,23-25=standard\n",
    "        Block C: 33=oddball, 31-32,34-35=standard\n",
    "        Block D: 44=oddball, 41-43,45=standard\n",
    "        Block E: 55=oddball, 51-54=standard\n",
    "        Response events (201, 202) are excluded\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(fn=self.transform, apply_on_array=False)\n",
    "\n",
    "    def transform(self, raw):\n",
    "        \"\"\"\n",
    "        Transform the raw data by selecting channels and mapping events.\n",
    "        \"\"\"\n",
    "        # Filter for stimulus events only\n",
    "        events, _ = mne.events_from_annotations(raw)\n",
    "\n",
    "        # Define oddball events (11,22,33,44,55)\n",
    "        oddball_codes = np.array([11, 22, 33, 44, 55])\n",
    "\n",
    "        # Map events: oddball=1, standard=0\n",
    "        oddball_mask = np.isin(events[:, 2], oddball_codes)\n",
    "        events[oddball_mask, 2] = 1\n",
    "        events[~oddball_mask, 2] = 0\n",
    "\n",
    "        # Print event counts for verification\n",
    "        oddball_count = np.sum(oddball_mask)\n",
    "        standard_count = len(events) - oddball_count\n",
    "        print(f\"\\nEvent distribution:\")\n",
    "        print(f\"Oddball events (11,22,33,44,55): {oddball_count}\")\n",
    "        print(f\"Standard events: {standard_count}\")\n",
    "\n",
    "        # Create annotations from events\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=events,\n",
    "            event_desc={0: \"standard\", 1: \"oddball\"},\n",
    "            sfreq=raw.info[\"sfreq\"],\n",
    "        )\n",
    "        raw.set_annotations(annot_from_events)\n",
    "\n",
    "        return raw\n",
    "\n",
    "\n",
    "# Create dataset from all files\n",
    "all_datasets = [\n",
    "    BaseDataset(read_raw_eeglab(f, preload=False), target_name=None)\n",
    "    for f in subject_files\n",
    "]\n",
    "dataset_concat = BaseConcatDataset(all_datasets)\n",
    "\n",
    "# BrainDecode preprocessors\n",
    "preprocessors = [\n",
    "    P3OddballPreprocessor(),\n",
    "    Preprocessor(\n",
    "        \"pick_channels\",\n",
    "        ch_names=read_raw_eeglab(subject_files[0], preload=False).ch_names[:30],\n",
    "    ),\n",
    "    Preprocessor(\"resample\", sfreq=256),\n",
    "    Preprocessor(\"filter\", l_freq=1, h_freq=55),\n",
    "]\n",
    "\n",
    "preprocess(dataset_concat, preprocessors)\n",
    "\n",
    "# Extract windows\n",
    "windows_ds = create_windows_from_events(\n",
    "    dataset_concat,\n",
    "    trial_start_offset_samples=26,\n",
    "    trial_stop_offset_samples=154,\n",
    "    preload=False,\n",
    "    window_size_samples=None,\n",
    "    window_stride_samples=None,\n",
    "    drop_bad_windows=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nAll files processed, total number of windows: {len(windows_ds)}\")\n",
    "print(f\"Window shape: {windows_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test Sets\n",
    "\n",
    "The data preparation pipeline consists of these key steps:\n",
    "\n",
    "1. **Data Extraction** - Windows are automatically labeled (0=standard, 1=oddball) by the P3OddballPreprocessor.\n",
    "\n",
    "2. **Train-Test Split** - Using sklearn's train_test_split with:\n",
    "   - 80-20 split ratio\n",
    "   - Stratified sampling to maintain class proportions\n",
    "   - Fixed random seed for reproducibility\n",
    "\n",
    "3. **PyTorch Data Preparation** - Converting to tensors and creating DataLoader objects for mini-batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 402\n",
      "Data shape: (402, 30, 128)\n",
      "Distribution of labels: (array([0, 1]), array([ 20, 382]))\n",
      "Label meanings: 0=standard, 1=oddball\n",
      "\n",
      "Dataset size:\n",
      "Training set: torch.Size([321, 30, 128]), labels: torch.Size([321])\n",
      "Test set: torch.Size([81, 30, 128]), labels: torch.Size([81])\n",
      "\n",
      "Proportion of samples of each class in training set:\n",
      "Category 0: 0.050\n",
      "Category 1: 0.950\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Extract data and labels using array operations\n",
    "data = np.stack([windows_ds[i][0] for i in range(len(windows_ds))])\n",
    "labels = np.array([windows_ds[i][1] for i in range(len(windows_ds))])\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset size: {len(data)}\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(\"Distribution of labels:\", np.unique(labels, return_counts=True))\n",
    "print(\"Label meanings: 0=standard, 1=oddball\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(data)), test_size=0.2, stratify=labels, random_state=random_state\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(data[train_indices])\n",
    "X_test = torch.FloatTensor(data[test_indices])\n",
    "y_train = torch.LongTensor(labels[train_indices])\n",
    "y_test = torch.LongTensor(labels[test_indices])\n",
    "\n",
    "# Create data loaders\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"\\nDataset size:\")\n",
    "print(f\"Training set: {X_train.shape}, labels: {y_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, labels: {y_test.shape}\")\n",
    "print(f\"\\nProportion of samples of each class in training set:\")\n",
    "for label in np.unique(labels):\n",
    "    ratio = np.mean(y_train.numpy() == label)\n",
    "    print(f\"Category {label}: {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "The model is a shallow convolutional neural network (ShallowFBCSPNet) with:\n",
    "- 30 input channels (EEG channels)\n",
    "- 2 output classes (oddball, standard)\n",
    "- 128-sample input windows (0.5s at 256Hz)\n",
    "\n",
    "This architecture is particularly effective for EEG classification tasks, incorporating frequency-band specific spatial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ShallowFBCSPNet                          [1, 2]                    --\n",
       "├─Ensure4d: 1-1                          [1, 30, 128, 1]           --\n",
       "├─Rearrange: 1-2                         [1, 1, 128, 30]           --\n",
       "├─CombinedConv: 1-3                      [1, 40, 104, 1]           49,040\n",
       "├─BatchNorm2d: 1-4                       [1, 40, 104, 1]           80\n",
       "├─Expression: 1-5                        [1, 40, 104, 1]           --\n",
       "├─AvgPool2d: 1-6                         [1, 40, 2, 1]             --\n",
       "├─Expression: 1-7                        [1, 40, 2, 1]             --\n",
       "├─Dropout: 1-8                           [1, 40, 2, 1]             --\n",
       "├─Sequential: 1-9                        [1, 2]                    --\n",
       "│    └─Conv2d: 2-1                       [1, 2, 1, 1]              162\n",
       "│    └─LogSoftmax: 2-2                   [1, 2, 1, 1]              --\n",
       "│    └─Expression: 2-3                   [1, 2]                    --\n",
       "==========================================================================================\n",
       "Total params: 49,282\n",
       "Trainable params: 49,282\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braindecode.models import ShallowFBCSPNet\n",
    "from torchinfo import summary\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans=30,\n",
    "    n_classes=2,\n",
    "    input_window_samples=128,  # 0.5s at 256Hz\n",
    "    final_conv_length=\"auto\",\n",
    ")\n",
    "\n",
    "summary(model, input_size=(1, 30, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "The training pipeline consists of:\n",
    "\n",
    "1. **Optimization Setup**:\n",
    "   - Adamax optimizer with learning rate 0.002\n",
    "   - Weight decay for regularization\n",
    "   - Learning rate scheduler\n",
    "\n",
    "2. **Training Process**:\n",
    "   - 5 epochs of training\n",
    "   - Mini-batch processing\n",
    "   - Cross-entropy loss function\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Accuracy tracking for both training and test sets\n",
    "   - Batch normalization applied to input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "epoch 1, training accuracy: 0.723, test accuracy: 0.926\n",
      "epoch 2, training accuracy: 0.897, test accuracy: 0.938\n",
      "epoch 3, training accuracy: 0.922, test accuracy: 0.951\n",
      "epoch 4, training accuracy: 0.931, test accuracy: 0.951\n",
      "epoch 5, training accuracy: 0.947, test accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.002, weight_decay=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n",
    "\n",
    "\n",
    "def normalize_data(x):\n",
    "    mean = x.mean(dim=2, keepdim=True)\n",
    "    std = x.std(dim=2, keepdim=True) + 1e-7\n",
    "    x = (x - mean) / std\n",
    "    x = x.to(device=device, dtype=torch.float32)\n",
    "    return x\n",
    "\n",
    "\n",
    "print(\"\\nStart training...\")\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    for t, (x, y) in enumerate(train_loader):\n",
    "        scores = model(normalize_data(x))\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        _, preds = scores.max(1)\n",
    "        correct_train += (preds == y).sum() / len(dataset_train)\n",
    "\n",
    "        loss = F.cross_entropy(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(test_loader):\n",
    "            scores = model(normalize_data(x))\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            _, preds = scores.max(1)\n",
    "            correct_test += (preds == y).sum() / len(dataset_test)\n",
    "\n",
    "    print(\n",
    "        f\"epoch {e + 1}, training accuracy: {correct_train:.3f}, test accuracy: {correct_test:.3f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegtemp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
