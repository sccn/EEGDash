{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification Tutorial: P3 Visual Oddball Task\n",
    "\n",
    "This tutorial demonstrates using the *EEGDash* library with PyTorch to classify EEG responses from a visual P3 oddball paradigm.\n",
    "\n",
    "1. **Data Description**: Dataset contains EEG recordings during a visual oddball task where:\n",
    "\n",
    "   - Letters A, B, C, D, and E were presented randomly (p = .2 for each)\n",
    "   - One letter was designated as target (oddball) for each block\n",
    "   - Other letters served as non-targets (standard)\n",
    "   - Participants responded whether each letter was target or non-target\n",
    "\n",
    "2. **Data Preprocessing**: \n",
    "\n",
    "   - Applies bandpass filtering (1-55 Hz)\n",
    "   - Selects first 30 EEG channels\n",
    "   - Downsamples from 1024Hz to 256Hz\n",
    "   - Creates event-based windows (0.1s to 0.6s post-stimulus)\n",
    "\n",
    "3. **Dataset Preparation**: \n",
    "\n",
    "   - Maps events into two classes:\n",
    "     * oddball: events where block target matches trial stimulus (11,22,33,44,55)\n",
    "     * standard: events where block target differs from trial stimulus\n",
    "     * Note: Response events (201, 202) are excluded\n",
    "   - Splits into training (80%) and test (20%) sets\n",
    "   - Creates PyTorch DataLoaders\n",
    "\n",
    "4. **Model**: \n",
    "\n",
    "   - ShallowFBCSPNet architecture\n",
    "   - 30 input channels, 2 output classes\n",
    "   - 128-sample input windows (0.5s at 256Hz)\n",
    "\n",
    "5. **Training**: \n",
    "\n",
    "   - Adamax optimizer with learning rate decay\n",
    "   - 5 training epochs\n",
    "   - Reports accuracy on train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval Using EEGDash\n",
    "\n",
    "The P3 Visual Oddball dataset is stored in BIDS format. We use EEGDash to load and manage the data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected files from subject-001:\n",
      "1. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\P3 Raw Data BIDS-Compatible\\sub-001\\eeg\\sub-001_task-P3_eeg.set\n"
     ]
    }
   ],
   "source": [
    "from eegdash.data_utils import EEGBIDSDataset\n",
    "\n",
    "dataset = EEGBIDSDataset(\n",
    "    data_dir='d:/Users/vivian/Desktop/UCSD/EEG/P3 Raw Data BIDS-Compatible',\n",
    "    dataset='P3 Raw Data BIDS-Compatible'\n",
    ")\n",
    "\n",
    "all_files = dataset.get_files()\n",
    "\n",
    "# Select files from subject-001\n",
    "subject_files = [f for f in all_files if 'sub-001' in f]\n",
    "print(\"\\nSelected files from subject-001:\")\n",
    "for i, file in enumerate(subject_files):\n",
    "    print(f\"{i+1}. {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Using Braindecode\n",
    "\n",
    "[Braindecode](https://braindecode.org/) provides powerful tools for EEG data preprocessing and analysis. Our implementation processes EEG data with these key steps:\n",
    "\n",
    "1. **Channel Selection & Signal Processing**:\n",
    "   - Selecting first 30 EEG channels\n",
    "   - Bandpass filtering between 1-55 Hz\n",
    "   - Downsampling from 1024Hz to 256Hz\n",
    "\n",
    "2. **Event Processing**:\n",
    "   - Reading events from events.tsv file:\n",
    "     * Block A: 11=oddball, 12-15=standard\n",
    "     * Block B: 22=oddball, 21,23-25=standard\n",
    "     * Block C: 33=oddball, 31-32,34-35=standard\n",
    "     * Block D: 44=oddball, 41-43,45=standard\n",
    "     * Block E: 55=oddball, 51-54=standard\n",
    "     * Response events (201, 202) are excluded\n",
    "\n",
    "3. **Window Creation**:\n",
    "\n",
    "   - Window duration: 1s\n",
    "   - Efficient memory usage with on-demand loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected 30 EEG channels:\n",
      "['FP1', 'F3', 'F7', 'FC3', 'C3', 'C5', 'P3', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Oz', 'Pz', 'CPz', 'FP2', 'Fz', 'F4', 'F8', 'FC4', 'FCz', 'Cz', 'C4', 'C6', 'P4', 'P8', 'P10', 'PO8', 'PO4', 'O2']\n",
      "\n",
      "Event distribution in sub-001_task-P3_eeg.set:\n",
      "Oddball events (11,22,33,44,55): 40\n",
      "Standard events: 160\n",
      "Total oddball events in sub-001_task-P3_eeg.set: 40\n",
      "Total standard events in sub-001_task-P3_eeg.set: 160\n",
      "\n",
      "Total number of windows created: 200\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import preprocess, Preprocessor, create_windows_from_events\n",
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "import warnings\n",
    "import logging\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from mne.io import read_raw_eeglab\n",
    "import pandas as pd\n",
    "\n",
    "mne.set_log_level('ERROR')  \n",
    "logging.getLogger('joblib').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class P3OddballPreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    A preprocessor that combines channel selection, filtering, event mapping,\n",
    "    and window creation for P3 oddball paradigm EEG data.\n",
    "    \n",
    "    Maps events based on block target and trial stimulus:\n",
    "        Block A: 11=oddball, 12-15=standard\n",
    "        Block B: 22=oddball, 21,23-25=standard\n",
    "        Block C: 33=oddball, 31-32,34-35=standard\n",
    "        Block D: 44=oddball, 41-43,45=standard\n",
    "        Block E: 55=oddball, 51-54=standard\n",
    "        Response events (201, 202) are excluded\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_channels, trial_start_offset_samples=26, trial_stop_offset_samples=154):\n",
    "        super().__init__(fn=self.transform, apply_on_array=False)\n",
    "        self.eeg_channels = eeg_channels\n",
    "        self.trial_start_offset_samples = trial_start_offset_samples\n",
    "        self.trial_stop_offset_samples = trial_stop_offset_samples\n",
    "        \n",
    "    def transform(self, raw, eeg_file=None):\n",
    "        \"\"\"\n",
    "        Transform the raw data by selecting channels, mapping events, and creating windows.\n",
    "        \"\"\"\n",
    "        # Select channels and apply filter\n",
    "        raw.pick_channels(self.eeg_channels)\n",
    "        raw.filter(l_freq=1, h_freq=55)\n",
    "        \n",
    "        # Resample to 256 Hz\n",
    "        raw.resample(256)\n",
    "        \n",
    "        # Read events from TSV file\n",
    "        events_file = os.path.join(os.path.dirname(eeg_file), os.path.basename(eeg_file).replace('_eeg.set', '_events.tsv'))\n",
    "        events_df = pd.read_csv(events_file, sep='\\t')\n",
    "        \n",
    "        # Filter for stimulus events only\n",
    "        stimulus_events = events_df[events_df['trial_type'] == 'stimulus']\n",
    "        \n",
    "        # Convert onset times to samples\n",
    "        sfreq = raw.info['sfreq']\n",
    "        onsets = (stimulus_events['onset'].values * sfreq).astype(int)\n",
    "        values = stimulus_events['value'].astype(int).values\n",
    "        \n",
    "        # Create events array\n",
    "        events = np.zeros((len(onsets), 3), dtype=int)\n",
    "        events[:, 0] = onsets  # Set onset times\n",
    "        \n",
    "        # Define oddball events (11,22,33,44,55)\n",
    "        oddball_codes = np.array([11, 22, 33, 44, 55])\n",
    "        \n",
    "        # Map events: oddball=1, standard=0\n",
    "        oddball_mask = np.isin(values, oddball_codes)\n",
    "        events[oddball_mask, 2] = 1\n",
    "        \n",
    "        # Print event counts for verification\n",
    "        oddball_count = np.sum(oddball_mask)\n",
    "        print(f\"\\nEvent distribution in {os.path.basename(eeg_file)}:\")\n",
    "        print(f\"Oddball events (11,22,33,44,55): {oddball_count}\")\n",
    "        print(f\"Standard events: {len(events) - oddball_count}\")\n",
    "        \n",
    "        # Create annotations from events\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=events,\n",
    "            event_desc={0: 'standard', 1: 'oddball'},\n",
    "            sfreq=sfreq\n",
    "        )\n",
    "        raw.set_annotations(annot_from_events)\n",
    "        oddball_count = np.sum(events[:, 2] == 1)\n",
    "        print(f\"Total oddball events in {os.path.basename(eeg_file)}: {oddball_count}\")\n",
    "        standard_count = len(events) - oddball_count\n",
    "        print(f\"Total standard events in {os.path.basename(eeg_file)}: {standard_count}\")\n",
    "        \n",
    "        # Create windows using single dataset\n",
    "        windows_ds = create_windows_from_events(\n",
    "            BaseConcatDataset([BaseDataset(raw, target_name=None)]),\n",
    "            trial_start_offset_samples=self.trial_start_offset_samples,\n",
    "            trial_stop_offset_samples=self.trial_stop_offset_samples,\n",
    "            preload=False,\n",
    "            window_size_samples=None,\n",
    "            window_stride_samples=None,\n",
    "            drop_bad_windows=True,\n",
    "            mapping={'standard': 0, 'oddball': 1}  \n",
    "        )\n",
    "        \n",
    "        return windows_ds\n",
    "\n",
    "# Get EEG channel names from first file\n",
    "raw = read_raw_eeglab(subject_files[0], preload=False)\n",
    "eeg_channels = raw.ch_names[:30]  \n",
    "print(\"\\nSelected 30 EEG channels:\")\n",
    "print(eeg_channels)\n",
    "\n",
    "# Process all files and combine datasets\n",
    "preprocessor = P3OddballPreprocessor(eeg_channels)\n",
    "all_windows = []\n",
    "\n",
    "# Process each file\n",
    "for file in subject_files:\n",
    "    raw = read_raw_eeglab(file, preload=True)\n",
    "    windows = preprocessor.transform(raw, file)\n",
    "    all_windows.extend(windows.datasets)\n",
    "\n",
    "# Combine all windows\n",
    "windows_ds = BaseConcatDataset(all_windows)\n",
    "print(\"\\nTotal number of windows created:\", len(windows_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test Sets\n",
    "\n",
    "The data preparation pipeline consists of these key steps:\n",
    "\n",
    "1. **Data Extraction** - Windows are automatically labeled (0=standard, 1=oddball) by the P3OddballPreprocessor.\n",
    "\n",
    "2. **Train-Test Split** - Using sklearn's train_test_split with:\n",
    "   - 80-20 split ratio\n",
    "   - Stratified sampling to maintain class proportions\n",
    "   - Fixed random seed for reproducibility\n",
    "\n",
    "3. **PyTorch Data Preparation** - Converting to tensors and creating DataLoader objects for mini-batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 200\n",
      "Data shape: (200, 30, 128)\n",
      "Distribution of labels: (array([0, 1]), array([160,  40]))\n",
      "Label meanings: 0=standard, 1=oddball\n",
      "\n",
      "Dataset size:\n",
      "Training set: torch.Size([160, 30, 128]), labels: torch.Size([160])\n",
      "Test set: torch.Size([40, 30, 128]), labels: torch.Size([40])\n",
      "\n",
      "Proportion of samples of each class in training set:\n",
      "Category 0: 0.800\n",
      "Category 1: 0.200\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Extract data and labels using array operations\n",
    "data = np.stack([windows_ds[i][0] for i in range(len(windows_ds))])\n",
    "labels = np.array([windows_ds[i][1] for i in range(len(windows_ds))])\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset size: {len(data)}\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(\"Distribution of labels:\", np.unique(labels, return_counts=True))\n",
    "print(\"Label meanings: 0=standard, 1=oddball\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(data)),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(data[train_indices])\n",
    "X_test = torch.FloatTensor(data[test_indices])\n",
    "y_train = torch.LongTensor(labels[train_indices])\n",
    "y_test = torch.LongTensor(labels[test_indices])\n",
    "\n",
    "# Create data loaders\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"\\nDataset size:\") \n",
    "print(f\"Training set: {X_train.shape}, labels: {y_train.shape}\") \n",
    "print(f\"Test set: {X_test.shape}, labels: {y_test.shape}\") \n",
    "print(f\"\\nProportion of samples of each class in training set:\") \n",
    "for label in np.unique(labels):\n",
    "    ratio = np.mean(y_train.numpy() == label)\n",
    "    print(f\"Category {label}: {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "\n",
    "The model is a shallow convolutional neural network (ShallowFBCSPNet) with:\n",
    "- 30 input channels (EEG channels)\n",
    "- 2 output classes (oddball, standard)\n",
    "- 128-sample input windows (0.5s at 256Hz)\n",
    "\n",
    "This architecture is particularly effective for EEG classification tasks, incorporating frequency-band specific spatial patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ShallowFBCSPNet                          [1, 2]                    --\n",
       "├─Ensure4d: 1-1                          [1, 30, 128, 1]           --\n",
       "├─Rearrange: 1-2                         [1, 1, 128, 30]           --\n",
       "├─CombinedConv: 1-3                      [1, 40, 104, 1]           49,040\n",
       "├─BatchNorm2d: 1-4                       [1, 40, 104, 1]           80\n",
       "├─Expression: 1-5                        [1, 40, 104, 1]           --\n",
       "├─AvgPool2d: 1-6                         [1, 40, 2, 1]             --\n",
       "├─Expression: 1-7                        [1, 40, 2, 1]             --\n",
       "├─Dropout: 1-8                           [1, 40, 2, 1]             --\n",
       "├─Sequential: 1-9                        [1, 2]                    --\n",
       "│    └─Conv2d: 2-1                       [1, 2, 1, 1]              162\n",
       "│    └─LogSoftmax: 2-2                   [1, 2, 1, 1]              --\n",
       "│    └─Expression: 2-3                   [1, 2]                    --\n",
       "==========================================================================================\n",
       "Total params: 49,282\n",
       "Trainable params: 49,282\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braindecode.models import ShallowFBCSPNet\n",
    "from torchinfo import summary\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans=30,       \n",
    "    n_classes=2,         \n",
    "    input_window_samples=128,  # 0.5s at 256Hz\n",
    "    final_conv_length=\"auto\"\n",
    ")\n",
    "\n",
    "summary(model, input_size=(1, 30, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "The training pipeline consists of:\n",
    "\n",
    "1. **Optimization Setup**:\n",
    "   - Adamax optimizer with learning rate 0.002\n",
    "   - Weight decay for regularization\n",
    "   - Learning rate scheduler\n",
    "\n",
    "2. **Training Process**:\n",
    "   - 5 epochs of training\n",
    "   - Mini-batch processing\n",
    "   - Cross-entropy loss function\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - Accuracy tracking for both training and test sets\n",
    "   - Batch normalization applied to input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "epoch 1, training accuracy: 0.606, test accuracy: 0.700\n",
      "epoch 2, training accuracy: 0.812, test accuracy: 0.775\n",
      "epoch 3, training accuracy: 0.837, test accuracy: 0.825\n",
      "epoch 4, training accuracy: 0.856, test accuracy: 0.775\n",
      "epoch 5, training accuracy: 0.875, test accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.002, weight_decay=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n",
    "\n",
    "def normalize_data(x):\n",
    "    mean = x.mean(dim=2, keepdim=True)\n",
    "    std = x.std(dim=2, keepdim=True) + 1e-7\n",
    "    x = (x - mean) / std\n",
    "    x = x.to(device=device, dtype=torch.float32)\n",
    "    return x\n",
    "\n",
    "print(\"\\nStart training...\")\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    for t, (x, y) in enumerate(train_loader):\n",
    "        scores = model(normalize_data(x))\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        _, preds = scores.max(1)\n",
    "        correct_train += (preds == y).sum()/len(dataset_train)\n",
    "        \n",
    "        loss = F.cross_entropy(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(test_loader):\n",
    "            scores = model(normalize_data(x))\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            _, preds = scores.max(1)\n",
    "            correct_test += (preds == y).sum()/len(dataset_test)\n",
    "    \n",
    "    print(f'epoch {e+1}, training accuracy: {correct_train:.3f}, test accuracy: {correct_test:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
