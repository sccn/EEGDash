{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGDash Example for Auditory Oddball Classification\n",
    "\n",
    "This code demonstrates using the *EEGDash* library with PyTorch to classify EEG responses in an auditory oddball paradigm.\n",
    "\n",
    "1. **Data Description**: Dataset contains EEG recordings during an auditory oddball task with two stimulus types:\n",
    "   - Standard: 500 Hz tone\n",
    "   - Oddball: 1000 Hz tone\n",
    "\n",
    "2. **Data Preprocessing**: \n",
    "   - Applies bandpass filtering (1-55 Hz)\n",
    "   - Selects 24 Channels\n",
    "   - Creates event-based windows\n",
    "   - Processes data in batches for memory efficiency\n",
    "\n",
    "3. **Dataset Preparation**: \n",
    "   - Remaps events into two classes: oddball, standard\n",
    "   - Splits into training (80%) and test (20%) sets\n",
    "   - Creates PyTorch DataLoaders\n",
    "\n",
    "4. **Model**: \n",
    "   - ShallowFBCSPNet architecture\n",
    "   - 24 input channels, 2 output classes\n",
    "   - 256-sample input windows\n",
    "\n",
    "5. **Training**: \n",
    "   - Adamax optimizer with learning rate decay\n",
    "   - 5 training epochs\n",
    "   - Reports accuracy on train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval Using EEGDash\n",
    "\n",
    "Data retrieved from https://nemar.org/dataexplorer/detail?dataset_id=ds003061.\n",
    "\n",
    "Download locally and change the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegdash.data_utils import EEGBIDSDataset\n",
    "\n",
    "dataset = EEGBIDSDataset(\n",
    "    data_dir='d:/Users/vivian/Desktop/UCSD/EEG/ds003061/ds003061',\n",
    "    dataset='ds003061'\n",
    ")\n",
    "\n",
    "all_files = dataset.get_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Using Braindecode\n",
    "\n",
    "[Braindecode](https://braindecode.org/) provides a powerful framework for EEG data preprocessing and analysis. This implementation processes EEG files in batches to efficiently manage memory usage while handling multiple recordings.\n",
    "\n",
    "The preprocessing pipeline consists of several key steps:\n",
    "\n",
    "1. **Batch Processing**: Files can be processed in small batches recordings to optimize memory usage and processing efficiency. Each batch is loaded, processed, and converted to windows before moving to the next batch.\n",
    "\n",
    "2. **Channel Selecting**: Select 24 specific EEG channels from the original 79.\n",
    "\n",
    "3. **Signal Filtering**: Bandpass filtering between 1 Hz and 55 Hz to remove noise and unwanted frequency components\n",
    "\n",
    "4. **Event Processing**: For each recording:\n",
    "   - Events are extracted from annotations using MNE's events_from_annotations\n",
    "   - The last event is removed to prevent time duration issues\n",
    "   - Events are then converted back to annotations with proper timing information\n",
    "\n",
    "5. **Window Creation**: The create_windows_from_events function extracts epochs from the continuous data:\n",
    "   - Windows are created with 128 samples before and after each event\n",
    "   - Data is loaded on demand (preload=False) to maintain memory efficiency\n",
    "   - Each window is automatically associated with its corresponding event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test files:\n",
      "1. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-1_eeg.set\n",
      "2. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-2_eeg.set\n",
      "3. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-3_eeg.set\n",
      "\n",
      " All batches processed, total number of windows: 2582\n",
      "Window shape: (24, 256)\n",
      "\n",
      "event mapping:\n",
      "Event number -> Event name:\n",
      "1 -> ignore\n",
      "2 -> noise\n",
      "3 -> oddball\n",
      "4 -> oddball_with_reponse\n",
      "5 -> response\n",
      "6 -> standard\n",
      "7 -> standard_with_reponse\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import preprocess, Preprocessor, create_windows_from_events\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab\n",
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "import warnings\n",
    "import mne\n",
    "import logging\n",
    "mne.set_log_level('ERROR')  \n",
    "logging.getLogger('joblib').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_files = all_files[0:3] # Select files from a single subject\n",
    "print(\"\\ntest files:\")\n",
    "for i, file in enumerate(test_files):\n",
    "    print(f\"{i+1}. {file}\")\n",
    "    \n",
    "\n",
    "batch_size = 1 # When selecting multiple subjects, it can be processed in batch to reduce memory usage.\n",
    "all_windows_datasets = [] \n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor('pick_channels', ch_names=[\n",
    "        'Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', \n",
    "        'O1', 'O2', 'F7', 'F8', 'T7', 'T8', 'P7', 'P8',\n",
    "        'Fz', 'Cz', 'Pz', 'Oz', 'FC1', 'FC2', 'CP1', 'CP2'\n",
    "    ]),\n",
    "    Preprocessor(\"filter\", l_freq=1, h_freq=55)\n",
    "]\n",
    "\n",
    "for batch_start in range(0, len(test_files), batch_size):\n",
    "    batch_end = batch_start + batch_size\n",
    "    batch_files = test_files[batch_start:batch_end]\n",
    "    batch_windows_datasets = []\n",
    "    \n",
    "    for i, file in enumerate(batch_files):\n",
    "        raw = read_raw_eeglab(file, preload=False)\n",
    "        raw_dataset = BaseDataset(raw, target_name=None)\n",
    "        single_ds = BaseConcatDataset([raw_dataset])\n",
    "        ds_preprocessed = preprocess(single_ds, preprocessors)\n",
    "        \n",
    "        raw = ds_preprocessed.datasets[0].raw\n",
    "        events, event_dict = mne.events_from_annotations(raw)\n",
    "        \n",
    "        # remove the last event to avoid time duration issues\n",
    "        events = events[:-1]\n",
    "        \n",
    "        # create a reverse mapping for event descriptions\n",
    "        reverse_event_dict = {v: k for k, v in event_dict.items()}\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=events,\n",
    "            event_desc=reverse_event_dict,  \n",
    "            sfreq=raw.info['sfreq']\n",
    "        )\n",
    "        raw.set_annotations(annot_from_events)\n",
    "        \n",
    "\n",
    "        # create windows from events\n",
    "        file_windows_ds = create_windows_from_events(\n",
    "            ds_preprocessed,\n",
    "            trial_start_offset_samples=-128,    \n",
    "            trial_stop_offset_samples=128,     \n",
    "            preload=False                 \n",
    "        )\n",
    "        batch_windows_datasets.extend(file_windows_ds.datasets)\n",
    "    \n",
    "    all_windows_datasets.extend(batch_windows_datasets)\n",
    "\n",
    "# combine all datasets into a single dataset\n",
    "windows_ds = BaseConcatDataset(all_windows_datasets)\n",
    "print(f\"\\n All batches processed, total number of windows: {len(windows_ds)}\") \n",
    "print(f\"Window shape: {windows_ds[0][0].shape}\")\n",
    "print(\"\\nevent mapping:\")\n",
    "print(\"Event number -> Event name:\")\n",
    "for event_name, event_number in event_dict.items():\n",
    "    print(f\"{event_number} -> {event_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and test sets\n",
    "\n",
    "The FilteredDataset class processes the windowed data by remapping event labels into two categories: oddball (0) and standard (1). The data preparation pipeline consists of these key steps:\n",
    "\n",
    "1. **Data Filtering and Label Remapping** - The FilteredDataset processes windows_ds by keeping only relevant events and mapping them to two categories. Labels 3,4 are mapped to oddball (0), and labels 6,7 to standard (1).\n",
    "\n",
    "2. **Train-Test Split** - Using sklearn's train_test_split, the dataset is divided into 80% training and 20% testing sets. The split is stratified to maintain class proportions across both sets.\n",
    "\n",
    "3. **PyTorch Data Preparation** - The split datasets are converted to PyTorch tensors and wrapped in DataLoader objects with a batch size of 10, enabling efficient training with shuffled mini-batches.\n",
    "\n",
    "The resulting training and test sets maintain balanced class distributions, ensuring representative samples for both model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset size:  1492\n",
      "Data shape: (1492, 24, 256)\n",
      "Distribution of labels after filtering and remapping: (array([0, 1]), array([970, 522]))\n",
      "Label meanings: 0=oddball, 1=standard\n",
      "\n",
      "Dataset size:\n",
      "Training set: torch.Size([1193, 24, 256]), labels: torch.Size([1193])\n",
      "Test set: torch.Size([299, 24, 256]), labels: torch.Size([299])\n",
      "\n",
      "Proportion of samples of each class in training set:\n",
      "Category 0: 0.650\n",
      "Category 1: 0.350\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# set random seed \n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "class FilteredDataset:\n",
    "    def __init__(self, windows_ds):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # remap labels according to the specified mapping\n",
    "        label_mapping = {\n",
    "            3: 0, 4: 0,  # oddball\n",
    "            6: 1, 7: 1   # standard\n",
    "        }\n",
    "        \n",
    "        for i in range(len(windows_ds)):\n",
    "            label = windows_ds[i][1]\n",
    "            if label in label_mapping:\n",
    "                self.data.append(windows_ds[i][0])\n",
    "                self.labels.append(label_mapping[label])\n",
    "        \n",
    "        self.data = np.array(self.data)\n",
    "        self.labels = np.array(self.labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# create a filtered dataset\n",
    "filtered_ds = FilteredDataset(windows_ds)\n",
    "print(f\"Filtered dataset size:  {len(filtered_ds)}\")\n",
    "print(f\"Data shape: {filtered_ds.data.shape}\")\n",
    "print(\"Distribution of labels after filtering and remapping:\", np.unique(filtered_ds.labels, return_counts=True))\n",
    "labels = filtered_ds.labels\n",
    "print(\"Label meanings: 0=oddball, 1=standard\")\n",
    "\n",
    "# divide the dataset into training and testing sets\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(filtered_ds)),\n",
    "    test_size=0.2,\n",
    "    stratify=filtered_ds.labels,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# convert data to PyTorch tensors\n",
    "X_train = torch.FloatTensor(filtered_ds.data[train_indices])\n",
    "X_test = torch.FloatTensor(filtered_ds.data[test_indices])\n",
    "y_train = torch.LongTensor(filtered_ds.labels[train_indices])\n",
    "y_test = torch.LongTensor(filtered_ds.labels[test_indices])\n",
    "\n",
    "# create data loaders\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# dataset information\n",
    "print(f\"\\nDataset size:\") \n",
    "print(f\"Training set: {X_train.shape}, labels: {y_train.shape}\") \n",
    "print(f\"Test set: {X_test.shape}, labels: {y_test.shape}\") \n",
    "print(f\"\\nProportion of samples of each class in training set:\") \n",
    "for label in np.unique(labels):\n",
    "    ratio = np.mean(y_train.numpy() == label)\n",
    "    print(f\"Category {label}: {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "The model is a shallow convolutional neural network (ShallowFBCSPNet) with 24 input channels (EEG channels), 2 output classes (oddball, standard), and an input window size of 256 samples (1 seconds of EEG data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ShallowFBCSPNet                          [1, 2]                    --\n",
       "├─Ensure4d: 1-1                          [1, 24, 256, 1]           --\n",
       "├─Rearrange: 1-2                         [1, 1, 256, 24]           --\n",
       "├─CombinedConv: 1-3                      [1, 40, 232, 1]           39,440\n",
       "├─BatchNorm2d: 1-4                       [1, 40, 232, 1]           80\n",
       "├─Expression: 1-5                        [1, 40, 232, 1]           --\n",
       "├─AvgPool2d: 1-6                         [1, 40, 11, 1]            --\n",
       "├─Expression: 1-7                        [1, 40, 11, 1]            --\n",
       "├─Dropout: 1-8                           [1, 40, 11, 1]            --\n",
       "├─Sequential: 1-9                        [1, 2]                    --\n",
       "│    └─Conv2d: 2-1                       [1, 2, 1, 1]              882\n",
       "│    └─LogSoftmax: 2-2                   [1, 2, 1, 1]              --\n",
       "│    └─Expression: 2-3                   [1, 2]                    --\n",
       "==========================================================================================\n",
       "Total params: 40,402\n",
       "Trainable params: 40,402\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.10\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braindecode.models import ShallowFBCSPNet\n",
    "from torchinfo import summary\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans=24,        \n",
    "    n_classes=2,         \n",
    "    input_window_samples=256,  \n",
    "    final_conv_length=\"auto\"\n",
    ")\n",
    "\n",
    "summary(model, input_size=(1, 24, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Process\n",
    "\n",
    "The training and evaluation pipeline runs for 5 epochs using Adamax optimization. Key components include:\n",
    "\n",
    "1. **Hardware Setup** - Model allocation to CPU/GPU for optimal computation.\n",
    "\n",
    "2. **Data Processing** - Channel-wise normalization of input data using mean and standard deviation.\n",
    "\n",
    "3. **Training Process** - Each epoch performs forward passes, computes cross-entropy loss, updates parameters, and tracks accuracy.\n",
    "\n",
    "4. **Evaluation** - Model performance is assessed on the test set after each training epoch.\n",
    "\n",
    "The process monitors both training and test accuracy to track model learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training...\n",
      "epoch 1, training accuracy: 0.637, test accuracy: 0.753\n",
      "epoch 2, training accuracy: 0.750, test accuracy: 0.789\n",
      "epoch 3, training accuracy: 0.795, test accuracy: 0.836\n",
      "epoch 4, training accuracy: 0.809, test accuracy: 0.846\n",
      "epoch 5, training accuracy: 0.838, test accuracy: 0.870\n"
     ]
    }
   ],
   "source": [
    "# set up the device, optimizer, and learning rate scheduler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.002, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n",
    "\n",
    "def normalize_data(x):\n",
    "    mean = x.mean(dim=2, keepdim=True)\n",
    "    std = x.std(dim=2, keepdim=True) + 1e-7\n",
    "    x = (x - mean) / std\n",
    "    x = x.to(device=device, dtype=torch.float32)\n",
    "    return x\n",
    "\n",
    "print(\"\\nstart training...\")\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    for t, (x, y) in enumerate(train_loader):\n",
    "        scores = model(normalize_data(x))\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        _, preds = scores.max(1)\n",
    "        correct_train += (preds == y).sum()/len(dataset_train)\n",
    "        \n",
    "        loss = F.cross_entropy(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(test_loader):\n",
    "            scores = model(normalize_data(x))\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            _, preds = scores.max(1)\n",
    "            correct_test += (preds == y).sum()/len(dataset_test)\n",
    "    \n",
    "    print(f'epoch {e+1}, training accuracy: {correct_train:.3f}, test accuracy: {correct_test:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegtemp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
