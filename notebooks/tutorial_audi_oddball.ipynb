{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEGDash Example for Auditory Oddball Classification\n",
    "\n",
    "This tutorial demonstrates using the *EEGDash* library with PyTorch to classify EEG responses in an auditory oddball paradigm.\n",
    "\n",
    "1. **Data Description**: Dataset contains EEG recordings during an auditory oddball task with two stimulus types:\n",
    "   - Standard: 500 Hz tone\n",
    "   - Oddball: 1000 Hz tone\n",
    "\n",
    "2. **Data Preprocessing**: \n",
    "   - Applies bandpass filtering (1-55 Hz)\n",
    "   - Selects all 64 EEG channels\n",
    "   - Creates event-based windows\n",
    "   - Processes data in batches for memory efficiency\n",
    "\n",
    "3. **Dataset Preparation**: \n",
    "   - Remaps events into two classes: oddball, standard\n",
    "   - Splits into training (80%) and test (20%) sets\n",
    "   - Creates PyTorch DataLoaders\n",
    "\n",
    "4. **Model**: \n",
    "   - ShallowFBCSPNet architecture\n",
    "   - 64 input channels, 2 output classes\n",
    "   - 256-sample input windows\n",
    "\n",
    "5. **Training**: \n",
    "   - Adamax optimizer with learning rate decay\n",
    "   - 5 training epochs\n",
    "   - Reports accuracy on train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval Using EEGDash\n",
    "\n",
    "Data retrieved from https://nemar.org/dataexplorer/detail?dataset_id=ds003061.\n",
    "\n",
    "Download locally and change the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eegdash.data_utils import EEGBIDSDataset\n",
    "\n",
    "dataset = EEGBIDSDataset(\n",
    "    data_dir='d:/Users/vivian/Desktop/UCSD/EEG/ds003061/ds003061',\n",
    "    dataset='ds003061'\n",
    ")\n",
    "\n",
    "all_files = dataset.get_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Using Braindecode\n",
    "\n",
    "[Braindecode](https://braindecode.org/) provides a powerful framework for EEG data preprocessing and analysis. This implementation efficiently processes EEG files with optimized memory usage.\n",
    "\n",
    "The preprocessing pipeline is encapsulated in the OddballPreprocessor class, which handles:\n",
    "\n",
    "1. **Channel Selection & Filtering**:\n",
    "   - Selecting first 64 EEG channels\n",
    "   - Bandpass filtering between 1 Hz and 55 Hz\n",
    "\n",
    "2. **Event Processing**:\n",
    "   - Event remapping using efficient array operations:\n",
    "     * 3,4 → oddball (0)\n",
    "     * 6,7 → standard (1)\n",
    "\n",
    "3. **Window Creation**:\n",
    "   - Creates 256-sample windows centered on events\n",
    "   - 128 samples before and after each event\n",
    "   - Efficient memory usage with on-demand loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test files:\n",
      "1. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-1_eeg.set\n",
      "2. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-2_eeg.set\n",
      "3. d:\\Users\\vivian\\Desktop\\UCSD\\EEG\\ds003061\\ds003061\\sub-001\\eeg\\sub-001_task-P300_run-3_eeg.set\n",
      "\n",
      "Selected 64 EEG channels:\n",
      "['Fp1', 'AF7', 'AF3', 'F1', 'F3', 'F5', 'F7', 'FT7', 'FC5', 'FC3', 'FC1', 'C1', 'C3', 'C5', 'T7', 'TP7', 'CP5', 'CP3', 'CP1', 'P1', 'P3', 'P5', 'P7', 'P9', 'PO7', 'PO3', 'O1', 'Iz', 'Oz', 'POz', 'Pz', 'CPz', 'Fpz', 'Fp2', 'AF8', 'AF4', 'AFz', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT8', 'FC6', 'FC4', 'FC2', 'FCz', 'Cz', 'C2', 'C4', 'C6', 'T8', 'TP8', 'CP6', 'CP4', 'CP2', 'P2', 'P4', 'P6', 'P8', 'P10', 'PO8', 'PO4', 'O2']\n",
      "\n",
      "All files processed, total number of windows: 1494\n",
      "Window shape: (64, 256)\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import preprocess, Preprocessor, create_windows_from_events\n",
    "import mne\n",
    "from mne.io import read_raw_eeglab\n",
    "from braindecode.datasets import BaseConcatDataset, BaseDataset\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "mne.set_log_level('ERROR')  \n",
    "logging.getLogger('joblib').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class OddballPreprocessor(Preprocessor):\n",
    "    \"\"\"\n",
    "    A preprocessor that combines channel selection, filtering, event mapping,\n",
    "    and window creation for auditory oddball paradigm EEG data.\n",
    "    \n",
    "    Maps events:\n",
    "        3,4 -> oddball (0)\n",
    "        6,7 -> standard (1)\n",
    "    \"\"\"\n",
    "    def __init__(self, eeg_channels, trial_start_offset_samples=-128, trial_stop_offset_samples=128):\n",
    "        super().__init__(fn=self.transform, apply_on_array=False)\n",
    "        self.eeg_channels = eeg_channels\n",
    "        self.trial_start_offset_samples = trial_start_offset_samples\n",
    "        self.trial_stop_offset_samples = trial_stop_offset_samples\n",
    "        \n",
    "    def transform(self, raw):\n",
    "        \"\"\"\n",
    "        Transform the raw data by selecting channels, mapping events, and creating windows.\n",
    "        \"\"\"\n",
    "        # Select channels and apply filter\n",
    "        raw.pick_channels(self.eeg_channels)\n",
    "        raw.filter(l_freq=1, h_freq=55)\n",
    "        \n",
    "        # Get events and event dictionary\n",
    "        events, _ = mne.events_from_annotations(raw)\n",
    "        \n",
    "        # Remove last event to avoid time duration issues\n",
    "        events = events[:-1]\n",
    "        \n",
    "        # Map events using boolean indexing\n",
    "        oddball_mask = np.isin(events[:, 2], [3, 4])\n",
    "        standard_mask = np.isin(events[:, 2], [6, 7])\n",
    "        \n",
    "        # Create new events array using array operations\n",
    "        new_events = np.zeros_like(events)\n",
    "        valid_mask = oddball_mask | standard_mask\n",
    "        new_events[valid_mask, 0] = events[valid_mask, 0]\n",
    "        new_events[standard_mask, 2] = 1  # standard events -> 1\n",
    "        \n",
    "        # Filter out invalid events\n",
    "        new_events = new_events[valid_mask]\n",
    "        \n",
    "        # Create annotations from events\n",
    "        annot_from_events = mne.annotations_from_events(\n",
    "            events=new_events,\n",
    "            event_desc={0: 'oddball', 1: 'standard'},\n",
    "            sfreq=raw.info['sfreq']\n",
    "        )\n",
    "        raw.set_annotations(annot_from_events)\n",
    "        \n",
    "        # Create windows using single dataset\n",
    "        windows_ds = create_windows_from_events(\n",
    "            BaseConcatDataset([BaseDataset(raw, target_name=None)]),\n",
    "            trial_start_offset_samples=self.trial_start_offset_samples,\n",
    "            trial_stop_offset_samples=self.trial_stop_offset_samples,\n",
    "            preload=False\n",
    "        )\n",
    "        \n",
    "        return windows_ds\n",
    "\n",
    "# Select files from a single subject\n",
    "test_files = all_files[0:3] \n",
    "print(\"\\ntest files:\")\n",
    "for i, file in enumerate(test_files):\n",
    "    print(f\"{i+1}. {file}\")\n",
    "\n",
    "# Get EEG channel names\n",
    "raw = read_raw_eeglab(test_files[0], preload=False)\n",
    "eeg_channels = raw.ch_names[:64]  # Get first 64 channel names\n",
    "print(\"\\nSelected 64 EEG channels:\")\n",
    "print(eeg_channels)\n",
    "\n",
    "# Process all files and combine datasets\n",
    "preprocessor = OddballPreprocessor(eeg_channels)\n",
    "all_windows = []\n",
    "\n",
    "# Process each file\n",
    "for file in test_files:\n",
    "    raw = read_raw_eeglab(file, preload=False)\n",
    "    windows = preprocessor.transform(raw)\n",
    "    all_windows.extend(windows.datasets)\n",
    "\n",
    "# Combine all windows\n",
    "windows_ds = BaseConcatDataset(all_windows)\n",
    "print(f\"\\nAll files processed, total number of windows: {len(windows_ds)}\") \n",
    "print(f\"Window shape: {windows_ds[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and test sets\n",
    "\n",
    "The data preparation pipeline consists of these key steps:\n",
    "\n",
    "1. **Dataset Creation** - The processed windows are automatically labeled (0=oddball, 1=standard) by the OddballPreprocessor using efficient array operations.\n",
    "\n",
    "2. **Train-Test Split** - Using sklearn's train_test_split with 80-20 split and stratified sampling.\n",
    "\n",
    "3. **PyTorch Data Preparation** - Converting to tensors and creating DataLoader objects for mini-batch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1494\n",
      "Data shape: (1494, 64, 256)\n",
      "Distribution of labels: (array([0, 1]), array([ 335, 1159]))\n",
      "Label meanings: 0=oddball, 1=standard\n",
      "\n",
      "Dataset size:\n",
      "Training set: torch.Size([1195, 64, 256]), labels: torch.Size([1195])\n",
      "Test set: torch.Size([299, 64, 256]), labels: torch.Size([299])\n",
      "\n",
      "Proportion of samples of each class in training set:\n",
      "Category 0: 0.224\n",
      "Category 1: 0.776\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_state = 42\n",
    "torch.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# Extract data and labels using array operations\n",
    "data = np.stack([windows_ds[i][0] for i in range(len(windows_ds))])\n",
    "labels = np.array([windows_ds[i][1] for i in range(len(windows_ds))])\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Dataset size: {len(data)}\")\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "print(\"Distribution of labels:\", np.unique(labels, return_counts=True))\n",
    "print(\"Label meanings: 0=oddball, 1=standard\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(data)),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.FloatTensor(data[train_indices])\n",
    "X_test = torch.FloatTensor(data[test_indices])\n",
    "y_train = torch.LongTensor(labels[train_indices])\n",
    "y_test = torch.LongTensor(labels[test_indices])\n",
    "\n",
    "# Create data loaders\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(dataset_train, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=10, shuffle=True)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"\\nDataset size:\") \n",
    "print(f\"Training set: {X_train.shape}, labels: {y_train.shape}\") \n",
    "print(f\"Test set: {X_test.shape}, labels: {y_test.shape}\") \n",
    "print(f\"\\nProportion of samples of each class in training set:\") \n",
    "for label in np.unique(labels):\n",
    "    ratio = np.mean(y_train.numpy() == label)\n",
    "    print(f\"Category {label}: {ratio:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "The model is a shallow convolutional neural network (ShallowFBCSPNet) with 64 input channels (EEG channels), 2 output classes (oddball, standard), and an input window size of 256 samples (1 seconds of EEG data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ShallowFBCSPNet                          [1, 2]                    --\n",
       "├─Ensure4d: 1-1                          [1, 64, 256, 1]           --\n",
       "├─Rearrange: 1-2                         [1, 1, 256, 64]           --\n",
       "├─CombinedConv: 1-3                      [1, 40, 232, 1]           103,440\n",
       "├─BatchNorm2d: 1-4                       [1, 40, 232, 1]           80\n",
       "├─Expression: 1-5                        [1, 40, 232, 1]           --\n",
       "├─AvgPool2d: 1-6                         [1, 40, 11, 1]            --\n",
       "├─Expression: 1-7                        [1, 40, 11, 1]            --\n",
       "├─Dropout: 1-8                           [1, 40, 11, 1]            --\n",
       "├─Sequential: 1-9                        [1, 2]                    --\n",
       "│    └─Conv2d: 2-1                       [1, 2, 1, 1]              882\n",
       "│    └─LogSoftmax: 2-2                   [1, 2, 1, 1]              --\n",
       "│    └─Expression: 2-3                   [1, 2]                    --\n",
       "==========================================================================================\n",
       "Total params: 104,402\n",
       "Trainable params: 104,402\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 0.07\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.14\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from braindecode.models import ShallowFBCSPNet\n",
    "from torchinfo import summary\n",
    "\n",
    "model = ShallowFBCSPNet(\n",
    "    in_chans=64,       \n",
    "    n_classes=2,         \n",
    "    input_window_samples=256,  \n",
    "    final_conv_length=\"auto\"\n",
    ")\n",
    "\n",
    "summary(model, input_size=(1, 64, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation Process\n",
    "\n",
    "The training and evaluation pipeline runs for 5 epochs using Adamax optimization. Key components include:\n",
    "\n",
    "1. **Hardware Setup** - Model allocation to CPU/GPU for optimal computation.\n",
    "\n",
    "2. **Data Processing** - Channel-wise normalization of input data using mean and standard deviation.\n",
    "\n",
    "3. **Training Process** - Each epoch performs forward passes, computes cross-entropy loss, updates parameters, and tracks accuracy.\n",
    "\n",
    "4. **Evaluation** - Model performance is assessed on the test set after each training epoch.\n",
    "\n",
    "The process monitors both training and test accuracy to track model learning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "epoch 1, training accuracy: 0.954, test accuracy: 0.913\n",
      "epoch 2, training accuracy: 0.960, test accuracy: 0.916\n",
      "epoch 3, training accuracy: 0.971, test accuracy: 0.930\n",
      "epoch 4, training accuracy: 0.976, test accuracy: 0.916\n",
      "epoch 5, training accuracy: 0.969, test accuracy: 0.930\n"
     ]
    }
   ],
   "source": [
    "# Set up device, optimizer, and learning rate scheduler\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n",
    "\n",
    "def normalize_data(x):\n",
    "    mean = x.mean(dim=2, keepdim=True)\n",
    "    std = x.std(dim=2, keepdim=True) + 1e-7\n",
    "    x = (x - mean) / std\n",
    "    x = x.to(device=device, dtype=torch.float32)\n",
    "    return x\n",
    "\n",
    "print(\"\\nStart training...\")\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    for t, (x, y) in enumerate(train_loader):\n",
    "        scores = model(normalize_data(x))\n",
    "        y = y.to(device=device, dtype=torch.long)\n",
    "        _, preds = scores.max(1)\n",
    "        correct_train += (preds == y).sum()/len(dataset_train)\n",
    "        \n",
    "        loss = F.cross_entropy(scores, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(test_loader):\n",
    "            scores = model(normalize_data(x))\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            _, preds = scores.max(1)\n",
    "            correct_test += (preds == y).sum()/len(dataset_test)\n",
    "    \n",
    "    print(f'epoch {e+1}, training accuracy: {correct_train:.3f}, test accuracy: {correct_test:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegtemp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
