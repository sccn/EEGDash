{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# EEG P3 Transfer Learning with AS-MMD\n\nThis tutorial demonstrates how to train a domain-adaptive deep learning model for\nEEG P3 component classification across two different datasets using Adaptive\nSymmetric Maximum Mean Discrepancy (AS-MMD).\n\n**Paper:** Chen, W., Delorme, A. (2025). Adaptive Split-MMD Training for Small-Sample\nCross-Dataset P300 EEG Classification. arXiv: [2510.21969](https://arxiv.org/abs/2510.21969)\n\n# Key Concepts\n\nThis tutorial covers:\n\n- **Domain Adaptation**: Training on multiple datasets with different recording setups\n- **Deep Learning**: Using EEGConformer, a transformer-based model for EEG\n- **AS-MMD**: A technique that aligns feature distributions across datasets\n- **Cross-Validation**: Robust evaluation using nested stratified folds\n\nBy the end, you'll understand how to:\n\n1. Load and preprocess multi-dataset EEG recordings\n2. Build a domain-adaptive classifier\n3. Evaluate performance across domains\n4. Apply the method to your own datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Loading and Preprocessing Data\n\nFirst, we load the datasets using EEGDashDataset. We'll use two public oddball\ndatasets:\n\n1. **ERP CORE P3**: 40 participants with active visual oddball paradigm\n   (Download: https://osf.io/etdkz/files \u2192 \"P3 Raw Data BIDS-Compatible\")\n\n2. **AVO (ds005863)**: 127 participants, available on OpenNeuro\n   (Download: https://openneuro.org/datasets/ds005863)\n\nThese datasets differ in equipment, recording sites, and participant demographics,\nmaking them ideal for testing domain adaptation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nfrom eegdash.dataset import DS005863\nfrom braindecode.datasets import MOABBDataset\n# Here, we are using an dataset that it in osf and other in openneuro.\n# We are conveniently using EEGDashDataset and MOABBDataset to load them.\n# but you can directly download from osf and use only EEGDashDataset if you prefer.\n\ncache_folder = Path.home() / \"eegdash\"\ncache_folder.mkdir(parents=True, exist_ok=True)\ncache_config = dict(\n    use=True,\n    save_raw=True,\n    path=cache_folder,\n)\n# Load datasets\nds_p3 = MOABBDataset(\n    dataset_name=\"ErpCore2021_P3\",\n    subject_ids=[i for i in range(1, 3)],  # all 5 subjects\n    dataset_load_kwargs={\"cache_config\": cache_config},\n)\n\n\nds_avo = DS005863(\n    cache_dir=cache_folder,\n    task=\"visualoddball\",\n    subject=[f\"{i:03d}\" for i in range(1, 3)],\n    download=True,\n)\n\nprint(f\"P3: {len(ds_p3)} recordings\")\nprint(f\"AVO: {len(ds_avo)} recordings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing Pipeline\n\nBefore training, we apply standard EEG preprocessing:\n\n- **Event labeling**: Identify oddball vs. standard stimuli\n- **Filtering**: 0.5-30 Hz bandpass to focus on relevant oscillations\n- **Resampling**: Downsample to 128 Hz to reduce computation\n- **Channel selection**: Keep Fz, Pz, P3, P4, Oz (standard P3 locations)\n- **Windowing**: Extract 1.2 sec epochs (-0.1s before to 1.1s after stimulus)\n- **Normalization**: Z-score normalization per trial\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nimport mne\nfrom braindecode.preprocessing import (\n    preprocess,\n    Preprocessor,\n    create_windows_from_events,\n)\n\nmne.set_log_level(\"ERROR\")\n\n# Preprocessing parameters\nLOW_FREQ = 0.5\nHIGH_FREQ = 30\nRESAMPLE_FREQ = 128\nTRIAL_START_OFFSET = -0.1  # 100 ms before stimulus\nTRIAL_DURATION = 1.1  # Total window 1.1 seconds\nCOMMON_CHANNELS = [\"Fz\", \"Pz\", \"P3\", \"P4\", \"Oz\"]\n\n\ndef preprocess_dataset(dataset, channels, dataset_type=\"P3\"):\n    \"\"\"Apply preprocessing pipeline to an EEG dataset.\n\n    Returns numpy arrays: (n_trials, n_channels, n_times)\n    \"\"\"\n    print(f\"\\nPreprocessing {dataset_type} dataset...\")\n\n    # Define preprocessing steps\n    preprocessors = [\n        Preprocessor(\"set_eeg_reference\", ref_channels=\"average\", projection=True),\n        Preprocessor(\"resample\", sfreq=RESAMPLE_FREQ),\n        Preprocessor(\"filter\", l_freq=LOW_FREQ, h_freq=HIGH_FREQ),\n        Preprocessor(\n            \"pick_channels\", ch_names=[ch.lower() for ch in channels], ordered=False\n        ),\n    ]\n\n    # Apply preprocessing\n    preprocess(dataset, preprocessors)\n\n    # Extract windowed trials around stimulus onset\n    trial_start = int(TRIAL_START_OFFSET * RESAMPLE_FREQ)\n    trial_stop = int((TRIAL_START_OFFSET + TRIAL_DURATION) * RESAMPLE_FREQ)\n\n    windows_ds = create_windows_from_events(\n        dataset,\n        trial_start_offset_samples=trial_start,\n        trial_stop_offset_samples=trial_stop,\n        preload=True,\n        drop_bad_windows=True,\n    )\n\n    X, y = [], []\n    for i in range(len(windows_ds)):\n        data, label, *_ = windows_ds[i]\n        X.append(data)\n        y.append(label)\n\n    print(f\"Extracted {len(X)} trials from {dataset_type}\")\n    return np.array(X), np.array(y)\n\n\n# Preprocess both datasets\nX_p3, y_p3 = preprocess_dataset(ds_p3, COMMON_CHANNELS, \"P3\")\nX_avo, y_avo = preprocess_dataset(ds_avo, COMMON_CHANNELS, \"AVO\")\n\n# Combine datasets for training\nX_all = np.vstack([X_p3, X_avo])\ny_all = np.hstack([y_p3, y_avo])\nsrc_all = np.array([\"P3\"] * len(X_p3) + [\"AVO\"] * len(X_avo))\n\nprint(f\"\\nCombined dataset: {len(X_all)} trials ({X_all.shape})\")\nprint(f\"  P3: {np.sum(src_all == 'P3')} trials\")\nprint(f\"  AVO: {np.sum(src_all == 'AVO')} trials\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Model Architecture and Training\n\n## Building the Domain-Adaptive Model\n\nWe use **EEGConformer**, a transformer-based architecture designed for EEG signals.\nThe key idea in AS-MMD is to combine:\n\n1. **Classification loss**: Standard cross-entropy on both domains\n2. **Domain alignment**: MMD loss to match feature distributions\n3. **Prototype alignment**: Align class centers across domains\n4. **Data augmentation**: Mixup + Gaussian noise for regularization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.models import EEGConformer\nimport torch.nn.functional as F\n\n\ndef normalize_data(x, eps=1e-7):\n    \"\"\"Normalize each trial independently.\"\"\"\n    mean = x.mean(dim=2, keepdim=True)\n    std = x.std(dim=2, keepdim=True)\n    std = torch.clamp(std, min=eps)\n    return (x - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Domain Adaptation Techniques\n\n**Mixup**: Interpolates between sample pairs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.4):\n    \"\"\"Mix samples from the same batch.\"\"\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1.0\n\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size, device=x.device)\n    mixed_x = lam * x + (1 - lam) * x[index]\n    return mixed_x, y, y[index], lam\n\n\n# **Focal Loss**: Down-weights easy examples\ndef compute_focal_loss(scores, targets, gamma=2.0, alpha=0.25):\n    \"\"\"Focal loss for class imbalance.\"\"\"\n    ce_loss = F.cross_entropy(scores, targets, reduction=\"none\")\n    pt = torch.exp(-ce_loss)\n    focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n    return focal_loss.mean()\n\n\n# **Maximum Mean Discrepancy**: Measures domain distribution mismatch\ndef compute_mmd_rbf(x, y, eps=1e-8):\n    \"\"\"RBF-kernel MMD for distribution alignment.\"\"\"\n    if x.dim() > 2:\n        x = x.view(x.size(0), -1)\n    if y.dim() > 2:\n        y = y.view(y.size(0), -1)\n\n    z = torch.cat([x, y], dim=0)\n    if z.size(0) > 1:\n        dists = torch.cdist(z, z, p=2.0)\n        sigma = torch.median(dists)\n        sigma = torch.clamp(sigma, min=eps)\n    else:\n        sigma = torch.tensor(1.0, device=z.device)\n\n    gamma = 1.0 / (2.0 * (sigma**2) + eps)\n    k_xx = torch.exp(-gamma * torch.cdist(x, x, p=2.0) ** 2)\n    k_yy = torch.exp(-gamma * torch.cdist(y, y, p=2.0) ** 2)\n    k_xy = torch.exp(-gamma * torch.cdist(x, y, p=2.0) ** 2)\n\n    m, n = x.size(0), y.size(0)\n    if m <= 1 or n <= 1:\n        return torch.tensor(0.0, device=x.device)\n\n    mmd = (k_xx.sum() - torch.trace(k_xx)) / (m * (m - 1) + eps)\n    mmd += (k_yy.sum() - torch.trace(k_yy)) / (n * (n - 1) + eps)\n    mmd -= 2.0 * k_xy.mean()\n    return mmd\n\n\n# **Prototype Alignment**: Align class centers across domains\ndef compute_prototypes(features, labels, n_classes=2):\n    \"\"\"Compute mean feature vector per class.\"\"\"\n    if features.dim() > 2:\n        features = features.view(features.size(0), -1)\n\n    prototypes = []\n    for c in range(n_classes):\n        mask = labels == c\n        if mask.sum() > 0:\n            proto = features[mask].mean(dim=0)\n        else:\n            proto = torch.zeros(features.size(1), device=features.device)\n        prototypes.append(proto)\n    return torch.stack(prototypes)\n\n\ndef compute_prototype_loss(features, labels, prototypes):\n    \"\"\"Align features to their class prototypes.\"\"\"\n    if features.dim() > 2:\n        features = features.view(features.size(0), -1)\n\n    loss = 0.0\n    for i, label in enumerate(labels):\n        proto = prototypes[label]\n        loss += F.mse_loss(features[i], proto)\n    return loss / max(1, len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Configuration\n\nDefine hyperparameters for stable cross-domain training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 22\nLEARNING_RATE = 0.001\nWEIGHT_DECAY = 2.5e-4\nMAX_EPOCHS = 100\nEARLY_STOPPING_PATIENCE = 10\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: Training and Evaluation\n\n## The Training Loop\n\nFor each batch, we compute four loss components:\n\n1. **Classification loss** (source + target): Standard cross-entropy\n2. **Mixup loss** (target domain): Interpolated samples for regularization\n3. **MMD loss**: Aligns logit-space feature distributions\n4. **Prototype loss**: Pulls small-domain features to large-domain class centers\n\nAll losses are combined with domain-adaptive weights that increase during training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.metrics import roc_auc_score\n\n\ndef evaluate_model(model, data_loader, device):\n    \"\"\"Evaluate model on a dataset and compute metrics.\"\"\"\n    model.eval()\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for x, y in data_loader:\n            x = normalize_data(x).to(device)\n            y = y.to(device)\n            scores = model(x)\n            all_preds.append(scores.argmax(1).cpu().numpy())\n            all_targets.append(y.cpu().numpy())\n            all_probs.append(torch.softmax(scores, dim=1)[:, 1].cpu().numpy())\n\n    preds = np.concatenate(all_preds)\n    targets = np.concatenate(all_targets)\n    probs = np.concatenate(all_probs)\n\n    accuracy = (preds == targets).mean()\n    auc = roc_auc_score(targets, probs) if len(np.unique(targets)) > 1 else 0.5\n\n    return {\"accuracy\": float(accuracy), \"auc\": float(auc)}\n\n\ndef make_loader(X, y, shuffle=False):\n    dataset = TensorDataset(torch.FloatTensor(X), torch.LongTensor(y))\n    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=shuffle)\n\n\ndef train_asmmd_model(\n    Xtr_p3,\n    ytr_p3,\n    Xva_p3,\n    yva_p3,\n    Xtr_avo,\n    ytr_avo,\n    Xva_avo,\n    yva_avo,\n    n_channels,\n    n_times,\n    seed=42,\n):\n    \"\"\"Train a single AS-MMD model.\n\n    Parameters\n    ----------\n    Xtr_*, ytr_* : numpy arrays\n        Training data and labels for each domain\n    Xva_*, yva_* : numpy arrays\n        Validation data and labels for each domain\n\n    \"\"\"\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n\n    # Create data loaders\n\n    train_p3 = make_loader(Xtr_p3, ytr_p3, shuffle=True)\n    val_p3 = make_loader(Xva_p3, yva_p3, shuffle=False)\n    train_avo = make_loader(Xtr_avo, ytr_avo, shuffle=True)\n    val_avo = make_loader(Xva_avo, yva_avo, shuffle=False)\n\n    # Initialize model\n    model = EEGConformer(\n        n_chans=n_channels,\n        n_outputs=2,  # Binary: oddball vs. standard\n        n_times=n_times,\n        n_filters_time=40,\n        filter_time_length=25,\n        pool_time_length=75,\n        pool_time_stride=15,\n        drop_prob=0.5,\n        att_depth=3,\n        att_heads=4,\n        att_drop_prob=0.5,\n    ).to(DEVICE)\n\n    optimizer = torch.optim.Adamax(\n        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n    )\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=MAX_EPOCHS)\n\n    # Compute domain-specific weights\n    n_p3, n_avo = len(Xtr_p3), len(Xtr_avo)\n    small_domain = \"P3\" if n_p3 < n_avo else \"AVO\"\n    large_domain = \"AVO\" if small_domain == \"P3\" else \"P3\"\n\n    # Training loop\n    best_score = 0.0\n    best_state = None\n    patience = 0\n\n    for epoch in range(1, MAX_EPOCHS + 1):\n        model.train()\n\n        # Warmup: gradually increase domain adaptation strength\n        warmup_epoch = min(1.0, epoch / 20)\n\n        loaders = {\"P3\": train_p3, \"AVO\": train_avo}\n        itr_small = iter(loaders[small_domain])\n\n        for xb_large, yb_large in loaders[large_domain]:\n            # Large domain batch\n            x_large = normalize_data(xb_large).to(DEVICE)\n            y_large = yb_large.to(DEVICE)\n            scores_large = model(x_large)\n            loss_cls = F.cross_entropy(scores_large, y_large)\n\n            # Small domain batch\n            try:\n                xb_small, yb_small = next(itr_small)\n            except StopIteration:\n                itr_small = iter(loaders[small_domain])\n                xb_small, yb_small = next(itr_small)\n\n            x_small = normalize_data(xb_small).to(DEVICE)\n            y_small = yb_small.to(DEVICE)\n\n            # Mixup on small domain\n            x_mixed, y_a, y_b, lam = mixup_data(x_small, y_small)\n            scores_mixed = model(x_mixed)\n            loss_mixup = lam * compute_focal_loss(scores_mixed, y_a) + (\n                1 - lam\n            ) * compute_focal_loss(scores_mixed, y_b)\n\n            # MMD alignment\n            scores_orig = model(x_small)\n            loss_mmd = warmup_epoch * compute_mmd_rbf(\n                scores_large.detach(), scores_orig.detach()\n            )\n\n            # Prototype alignment\n            with torch.no_grad():\n                proto_large = compute_prototypes(\n                    scores_large.detach(), y_large, n_classes=2\n                )\n            loss_proto = warmup_epoch * compute_prototype_loss(\n                scores_orig, y_small, proto_large\n            )\n\n            # Combined loss\n            loss = loss_cls + loss_mixup + 0.3 * loss_mmd + 0.5 * loss_proto\n\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n            optimizer.step()\n\n        scheduler.step()\n\n        # Validation\n        val_p3_metrics = evaluate_model(model, val_p3, DEVICE)\n        val_avo_metrics = evaluate_model(model, val_avo, DEVICE)\n\n        # Track best model on small domain\n        small_val = (\n            val_p3_metrics[\"accuracy\"]\n            if small_domain == \"P3\"\n            else val_avo_metrics[\"accuracy\"]\n        )\n\n        if small_val > best_score:\n            best_score = small_val\n            best_state = model.state_dict()\n            patience = 0\n        else:\n            patience += 1\n\n        if (epoch % 10 == 0) or (epoch == 1):\n            print(\n                f\"Epoch {epoch:3d} | P3 val: {val_p3_metrics['accuracy']:.3f} | \"\n                f\"AVO val: {val_avo_metrics['accuracy']:.3f} | Score: {small_val:.3f}\"\n            )\n\n        if patience >= EARLY_STOPPING_PATIENCE:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n    # Load best model\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nested Cross-Validation\n\nWe use nested CV to robustly estimate model performance:\n\n- **Outer folds (5)**: For test set evaluation\n- **Inner split**: Train/val split for hyperparameter tuning\n- **Repeats (5)**: Multiple random seeds for stability\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, train_test_split\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n\ndef run_nested_cv(X_all, y_all, src_all, channels):\n    \"\"\"Run nested cross-validation with AS-MMD.\"\"\"\n    n_channels = X_all.shape[1]\n    n_times = X_all.shape[2]\n\n    results = []\n    SEEDS = [42, 123, 456, 789, 321]\n\n    for repeat in range(2):  # 2 repeats for quick demo (use 5 for final results)\n        print(f\"\\n{'=' * 60}\")\n        print(f\"Repeat {repeat + 1}/2\")\n        print(\"=\" * 60)\n\n        cv = StratifiedKFold(\n            n_splits=3, shuffle=True, random_state=SEEDS[repeat]\n        )  # 3 folds for demo\n\n        for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X_all, y_all)):\n            print(f\"\\nFold {fold_idx + 1}/3\")\n\n            X_tr, y_tr, src_tr = X_all[train_idx], y_all[train_idx], src_all[train_idx]\n            X_te, y_te, src_te = X_all[test_idx], y_all[test_idx], src_all[test_idx]\n\n            # Split train into train/val\n            tr_idx, va_idx = train_test_split(\n                np.arange(len(X_tr)), test_size=0.15, stratify=y_tr, random_state=42\n            )\n\n            # Extract per-domain data\n            def get_domain(X, y, src, idx, domain):\n                mask = src == domain\n                indices = np.intersect1d(np.where(mask)[0], idx)\n                return X[indices], y[indices]\n\n            Xtr_p3, ytr_p3 = get_domain(X_tr, y_tr, src_tr, tr_idx, \"P3\")\n            Xtr_avo, ytr_avo = get_domain(X_tr, y_tr, src_tr, tr_idx, \"AVO\")\n            Xva_p3, yva_p3 = get_domain(X_tr, y_tr, src_tr, va_idx, \"P3\")\n            Xva_avo, yva_avo = get_domain(X_tr, y_tr, src_tr, va_idx, \"AVO\")\n\n            if len(Xtr_p3) == 0 or len(Xtr_avo) == 0:\n                print(\"  Skipping: insufficient training samples\")\n                continue\n\n            print(f\"  Train: P3={len(Xtr_p3)}, AVO={len(Xtr_avo)}\")\n            print(f\"  Val:   P3={len(Xva_p3)}, AVO={len(Xva_avo)}\")\n\n            # Train model\n            model = train_asmmd_model(\n                Xtr_p3,\n                ytr_p3,\n                Xva_p3,\n                yva_p3,\n                Xtr_avo,\n                ytr_avo,\n                Xva_avo,\n                yva_avo,\n                n_channels,\n                n_times,\n                seed=SEEDS[repeat],\n            )\n\n            # Evaluate on test set\n            def test_domain(domain_label):\n                mask = src_te == domain_label\n                if not np.any(mask):\n                    return {\"accuracy\": 0.0, \"auc\": 0.5}, 0\n                loader = make_loader(X_te[mask], y_te[mask])\n                metrics = evaluate_model(model, loader, DEVICE)\n                return metrics, np.sum(mask)\n\n            def make_loader(X, y):\n                return DataLoader(\n                    TensorDataset(torch.FloatTensor(X), torch.LongTensor(y)),\n                    batch_size=BATCH_SIZE,\n                    shuffle=False,\n                )\n\n            m_p3, n_p3 = test_domain(\"P3\")\n            m_avo, n_avo = test_domain(\"AVO\")\n\n            overall_acc = (m_p3[\"accuracy\"] * n_p3 + m_avo[\"accuracy\"] * n_avo) / (\n                n_p3 + n_avo + 1e-8\n            )\n\n            print(\n                f\"  Test: P3={m_p3['accuracy']:.3f} (n={n_p3}), AVO={m_avo['accuracy']:.3f} (n={n_avo})\"\n            )\n\n            results.append(\n                {\n                    \"repeat\": repeat + 1,\n                    \"fold\": fold_idx + 1,\n                    \"p3_acc\": m_p3[\"accuracy\"],\n                    \"p3_auc\": m_p3[\"auc\"],\n                    \"avo_acc\": m_avo[\"accuracy\"],\n                    \"avo_auc\": m_avo[\"auc\"],\n                    \"overall_acc\": overall_acc,\n                }\n            )\n\n    return pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute Training\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nStarting AS-MMD Training with Nested Cross-Validation...\")\nprint(\"=\" * 60)\n\nresults_df = run_nested_cv(X_all, y_all, src_all, COMMON_CHANNELS)\n\n# Print summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"RESULTS SUMMARY\")\nprint(\"=\" * 60)\nprint(\n    f\"\\nOverall Accuracy: {results_df['overall_acc'].mean():.4f} \u00b1 {results_df['overall_acc'].std():.4f}\"\n)\nprint(\"\\nP3 Dataset:\")\nprint(\n    f\"  Accuracy: {results_df['p3_acc'].mean():.4f} \u00b1 {results_df['p3_acc'].std():.4f}\"\n)\nprint(f\"  AUC: {results_df['p3_auc'].mean():.4f} \u00b1 {results_df['p3_auc'].std():.4f}\")\nprint(\"\\nAVO Dataset:\")\nprint(\n    f\"  Accuracy: {results_df['avo_acc'].mean():.4f} \u00b1 {results_df['avo_acc'].std():.4f}\"\n)\nprint(f\"  AUC: {results_df['avo_auc'].mean():.4f} \u00b1 {results_df['avo_auc'].std():.4f}\")\nprint(\"=\" * 60)\n\n# Save results\nresults_df.to_csv(\"asmmd_results.csv\", index=False)\nprint(\"\\nResults saved to: asmmd_results.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Key Takeaways\n\n**Main Components of AS-MMD:**\n\n1. **Classification Loss**: Standard cross-entropy on both datasets\n2. **Mixup Regularization**: Interpolate between samples for better generalization\n3. **MMD Alignment**: Match feature distributions across domains\n4. **Prototype Alignment**: Pull small-domain features toward large-domain class centers\n5. **Warmup Schedule**: Gradually introduce domain adaptation during training\n\n**When to Use This Method:**\n\n- You have limited data from your target domain\n- You have access to a related source domain (different equipment/site)\n- You want a single model that performs well on both domains\n- You need robust cross-dataset performance\n\n**Tips for Your Own Data:**\n\n- Verify channel names match between datasets (case-insensitive lowercasing helps)\n- Adjust BATCH_SIZE if memory is limited (try 16 or 32)\n- Increase MAX_EPOCHS if curves haven't plateaued\n- Tune MMD weight (0.2-0.5) and prototype weight (0.5-0.8) based on domain similarity\n- Use more CV folds (5-10) for final results\n\n**References:**\n\n- Chen, W., Delorme, A. (2025). Adaptive Split-MMD Training for Small-Sample Cross-Dataset P300 Classification.\n- Song et al. (2019). \"EEGConformer: Convolutional Transformer for EEG Decoding\"\n- Long et al. (2015). \"Learning Transferable Features with Deep Adaptation Networks\"\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Next Steps\n\n- Try different EEG components (e.g., N1, P2, N2 instead of P3)\n- Extend to multi-class classification (e.g., oddball paradigm variants)\n- Apply to other tasks (motor imagery, sleep staging, seizure detection)\n- Experiment with other backbones (ResNet, LSTM) instead of EEGConformer\n- Implement subject-independent vs. subject-specific models\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}