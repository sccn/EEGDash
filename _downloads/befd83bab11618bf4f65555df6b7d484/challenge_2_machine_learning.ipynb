{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Predicting p-factor from EEG - Example\n\n# Tutorial for Predicting p-factor from EEG - EEG 2025 Competition\n\nThis tutorial demonstrates how to load EEG data for the p-factor prediction task from the EEG 2025 competition, extract epochs, and calculate response times and correctness information. We'll use `EEGDash` and `braindecode`.\n\n## Key Features:\n\nThe code below provides an example of using the *braindecode* and *EEGDash* libraries in combination with LightGBM to predict a subject's p-factor.\n\n1. **Data Retrieval Using EEGDash**: An instance of *EEGDashDataset* is created to search and retrieve resting state data. At this step, only the metadata is transferred.\n\n2. **Data Preprocessing Using BrainDecode**: This process preprocesses EEG data using Braindecode by selecting specific channels, resampling, filtering, and extracting 10-second epochs.\n\n3. **Extracting EEG Features Using EEGDash.features**: Building a feature extraction tree and extracting features per EEG window.\n\n4. **Model Training and Evaluation Process**: This section normalizes input data, trains a LightGBM model, and evaluates regression MSE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from eegdash import EEGDashDataset\n\n# hbn_datasets_train = ['ds005505', 'ds005506', 'ds005507', 'ds005508', 'ds005510', 'ds005511', 'ds005512', 'ds005514', 'ds005515', 'ds005516']\nhbn_datasets_train = [\"ds005505\", \"ds005506\", \"ds005507\"]\nhbn_datasets_valid = [\"ds005509\"]\n\ntask_name = \"RestingState\"\ntarget_name = \"p_factor\"\ndesc_fields = [\n    \"subject_id\",\n    \"session_id\",\n    \"run_id\",\n    \"task_name\",\n    \"target_name\",\n]\n\ndatasets_train = [\n    EEGDashDataset(\n        {\"dataset\": ds, \"task\": task_name},\n        description_fields=desc_fields,\n        target_name=target_name,\n    )\n    for ds in hbn_datasets_train\n]\ndatasets_valid = [\n    EEGDashDataset(\n        {\"dataset\": ds, \"task\": task_name},\n        description_fields=desc_fields,\n        target_name=target_name,\n    )\n    for ds in hbn_datasets_valid\n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from braindecode.datasets import BaseConcatDataset\n\nraw_train = BaseConcatDataset(\n    [ds for dataset in datasets_train for ds in dataset.datasets]\n)\nraw_valid = BaseConcatDataset(\n    [ds for dataset in datasets_valid for ds in dataset.datasets]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing Using Braindecode\n\n[BrainDecode](https://braindecode.org/stable/install/install.html) is a specialized library for preprocessing EEG and MEG data.\n\nWe apply three preprocessing steps in Braindecode:\n1.\t**Selection** of 24 specific EEG channels from the original 128.\n2.\t**Resampling** the EEG data to a frequency of 128 Hz.\n3.\t**Filtering** the EEG signals to retain frequencies between 1 Hz and 55 Hz.\n\nWhen calling the **preprocess** function, the data is retrieved from the remote repository.\n\nFinally, we use **create_windows_from_events** to extract 10-second epochs from the data. These epochs serve as the dataset samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom braindecode.preprocessing import (\n    preprocess,\n    Preprocessor,\n    create_fixed_length_windows,\n)\n\n\ndef preprocess_and_window(raw_ds):\n    # preprocessing using a Braindecode pipeline:\n    preprocessors = [\n        Preprocessor(\n            \"pick_channels\",\n            ch_names=[\n                \"E22\",\n                \"E9\",\n                \"E33\",\n                \"E24\",\n                \"E11\",\n                \"E124\",\n                \"E122\",\n                \"E29\",\n                \"E6\",\n                \"E111\",\n                \"E45\",\n                \"E36\",\n                \"E104\",\n                \"E108\",\n                \"E42\",\n                \"E55\",\n                \"E93\",\n                \"E58\",\n                \"E52\",\n                \"E62\",\n                \"E92\",\n                \"E96\",\n                \"E70\",\n                \"Cz\",\n            ],\n        ),\n        Preprocessor(\"resample\", sfreq=128),\n        Preprocessor(\"filter\", l_freq=1, h_freq=55),\n    ]\n    preprocess(raw_ds, preprocessors, n_jobs=-1)\n\n    # extract windows and save to disk\n    sfreq = raw_ds.datasets[0].raw.info[\"sfreq\"]\n    windows_ds = create_fixed_length_windows(\n        raw_ds,\n        start_offset_samples=0,\n        stop_offset_samples=None,\n        window_size_samples=int(10 * sfreq),\n        window_stride_samples=int(5 * sfreq),\n        drop_last_window=True,\n        preload=False,\n    )\n    return windows_ds\n\n\nwindows_train = preprocess_and_window(raw_train)\nos.makedirs(f\"data/hbn_preprocessed_{task_name}_train\", exist_ok=True)\nwindows_train.save(f\"data/hbn_preprocessed_{task_name}_train\", overwrite=True)\n\nwindows_valid = preprocess_and_window(raw_valid)\nos.makedirs(f\"data/hbn_preprocessed_{task_name}_valid\", exist_ok=True)\nwindows_valid.save(f\"data/hbn_preprocessed_{task_name}_valid\", overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting EEG Features Using EEGDash.features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from eegdash import features\nfrom eegdash.features import extract_features\nfrom functools import partial\n\nsfreq = windows_train.datasets[0].raw.info[\"sfreq\"]\nfilter_freqs = dict(windows_train.datasets[0].raw_preproc_kwargs)[\"filter\"]\nfeatures_dict = {\n    \"sig\": features.FeatureExtractor(\n        {\n            \"std\": features.signal_std,\n            \"line_len\": features.signal_line_length,\n            \"zero_x\": features.signal_zero_crossings,\n        },\n    ),\n    \"spec\": features.SpectralFeatureExtractor(\n        {\n            \"rtot_power\": features.spectral_root_total_power,\n            \"band_power\": features.spectral_bands_power,\n            0: features.NormalizedSpectralFeatureExtractor(\n                {\n                    \"moment\": features.spectral_moment,\n                    \"entropy\": features.spectral_entropy,\n                    \"edge\": partial(features.spectral_edge, edge=0.9),\n                },\n            ),\n            1: features.DBSpectralFeatureExtractor(\n                {\n                    \"slope\": features.spectral_slope,\n                },\n            ),\n        },\n        fs=sfreq,\n        f_min=filter_freqs[\"l_freq\"],\n        f_max=filter_freqs[\"h_freq\"],\n        nperseg=4 * sfreq,\n        noverlap=3 * sfreq,\n    ),\n}\n\nfeatures_train = extract_features(\n    windows_train, features_dict, batch_size=64, n_jobs=-1\n)\nos.makedirs(f\"data/hbn_features_{task_name}_train\", exist_ok=True)\nfeatures_train.save(f\"data/hbn_features_{task_name}_train\", overwrite=True)\n\nfeatures_valid = extract_features(\n    windows_valid, features_dict, batch_size=64, n_jobs=-1\n)\nos.makedirs(f\"data/hbn_features_{task_name}_valid\", exist_ok=True)\nfeatures_valid.save(f\"data/hbn_features_{task_name}_valid\", overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features_train.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Replace Inf and NaN values:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfeatures_train.replace([-np.inf, +np.inf], np.nan)\nfeatures_train.fillna(0)\n\nfeatures_valid.replace([-np.inf, +np.inf], np.nan)\nfeatures_valid.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features_train.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert to pandas dataframes and normalize:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mean_train = features_train.mean(n_jobs=-1)\nstd_train = features_train.std(eps=1e-14, n_jobs=-1)\n\nX_train = features_train.to_dataframe()\nX_train = (X_train - mean_train) / std_train\ny_train = features_train.get_metadata()[\"target\"]\n\nX_valid = features_valid.to_dataframe()\nX_valid = (X_valid - mean_train) / std_train\ny_valid = features_valid.get_metadata()[\"target\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor, record_evaluation\n\nrandom_seed = 137\n\nmodel = LGBMRegressor(\n    random_state=random_seed,\n    n_jobs=-1,\n    n_estimators=10000,\n    num_leaves=5,\n    max_depth=2,\n    min_data_in_leaf=4,\n    learning_rate=0.1,\n    early_stopping_round=5,\n    first_metric_only=True,\n)\n\neval_results = dict()\nmodel.fit(\n    X_train,\n    y_train,\n    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n    eval_names=[\"train\", \"validation\"],\n    eval_metric=\"l2\",\n    callbacks=[record_evaluation(eval_results)],\n)\n\ny_hat_train = model.predict(X_train)\ncorrect_train = ((y_train - y_hat_train) ** 2).mean()\ny_hat_valid = model.predict(X_valid)\ncorrect_valid = ((y_valid - y_hat_valid) ** 2).mean()\nprint(f\"Train MSE: {correct_train:.2f}, Validation MSE: {correct_valid:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lightgbm import plot_metric\n\nplot_metric(model, \"l2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lightgbm import plot_importance\n\nplot_importance(model, importance_type=\"split\", max_num_features=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_importance(model, importance_type=\"gain\", max_num_features=10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}