{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# EEGDash Feature Extractor\n\nEEGDash example for eyes open vs. closed classification.\n\nThis example uses the :mod:`eegdash` library in combination with PyTorch to develop a deep learning model for analyzing EEG data, specifically for eyes open vs. closed classification in a single subject.\n\n1. **Data Retrieval Using EEGDash**: An instance of :class:`eegdash.api.EEGDashDataset` is created to search and retrieve an EEG dataset. At this step, only the metadata is transferred.\n\n2. **Data Preprocessing Using BrainDecode**: This process preprocesses EEG data using Braindecode by reannotating events, selecting specific channels, resampling, filtering, and extracting 2-second epochs, ensuring balanced eyes-open and eyes-closed data for analysis.\n\n3. **Creating train and testing sets**: The dataset is split into training (80%) and testing (20%) sets with balanced labels, converted into PyTorch tensors, and wrapped in DataLoader objects for efficient mini-batch training.\n\n4. **Model Definition**: The model is a shallow convolutional neural network (ShallowFBCSPNet) with 24 input channels (EEG channels), 2 output classes (eyes-open and eyes-closed).\n\n5. **Model Training and Evaluation Process**: This section trains the neural network, normalizes input data, computes cross-entropy loss, updates model parameters, and evaluates classification accuracy over six epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Retrieval Using EEGDash\n\nWe instantiate :class:`eegdash.api.EEGDashDataset` to pull the experiment\nmetadata and build the dataset definition.\n\nFirst we find one resting state dataset. This dataset contains both eyes open\nand eyes closed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n\nfrom eegdash import EEGDashDataset\n\ncache_folder = Path.home() / \"eegdash\"\n\nds_eoec = EEGDashDataset(\n    dataset=\"ds005514\",\n    task=\"RestingState\",\n    subject=\"NDARDB033FW5\",\n    cache_dir=cache_folder,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing Using Braindecode\n\n[BrainDecode](https://braindecode.org/stable/install/install.html) is a\nspecialized library for preprocessing EEG and MEG data. In this dataset, there\nare two key events in the continuous data: **instructed_toCloseEyes**, marking\nthe start of a 40-second eyes-closed period, and **instructed_toOpenEyes**,\nindicating the start of a 20-second eyes-open period.\n\nFor the eyes-closed event, we extract 14 seconds of data from 15 to 29 seconds\nafter the event onset. Similarly, for the eyes-open event, we extract data\nfrom 5 to 19 seconds after the event onset. This ensures an equal amount of\ndata for both conditions. The event extraction is handled by the custom\nfunction :func:`eegdash.hbn.preprocessing.hbn_ec_ec_reannotation`.\n\nNext, we apply four preprocessing steps in Braindecode:\n1. **Reannotation** of event markers using :func:`eegdash.hbn.preprocessing.hbn_ec_ec_reannotation`.\n2. **Selection** of 24 specific EEG channels from the original 128.\n3. **Resampling** the EEG data to a frequency of 128 Hz.\n4. **Filtering** the EEG signals to retain frequencies between 1 Hz and 55 Hz.\n\nWhen calling the `preprocess` function, the data is retrieved from the remote\nrepository.\n\nFinally, we use `create_windows_from_events` to extract 2-second epochs from\nthe data. These epochs serve as the dataset samples. At this stage, each\nsample is automatically labeled with the corresponding event type (eyes-open\nor eyes-closed). `windows_ds` is a PyTorch dataset, and when queried, it\nreturns labels for eyes-open and eyes-closed (assigned as labels 0 and 1,\ncorresponding to their respective event markers).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from eegdash.hbn.preprocessing import hbn_ec_ec_reannotation\nfrom braindecode.preprocessing import (\n    preprocess,\n    Preprocessor,\n    create_windows_from_events,\n)\nimport numpy as np\nimport warnings\n\nwarnings.simplefilter(\"ignore\", category=RuntimeWarning)\n\n\n# BrainDecode preprocessors\npreprocessors = [\n    hbn_ec_ec_reannotation(),\n    Preprocessor(\n        \"pick_channels\",\n        ch_names=[\n            \"E22\",\n            \"E9\",\n            \"E33\",\n            \"E24\",\n            \"E11\",\n            \"E124\",\n            \"E122\",\n            \"E29\",\n            \"E6\",\n            \"E111\",\n            \"E45\",\n            \"E36\",\n            \"E104\",\n            \"E108\",\n            \"E42\",\n            \"E55\",\n            \"E93\",\n            \"E58\",\n            \"E52\",\n            \"E62\",\n            \"E92\",\n            \"E96\",\n            \"E70\",\n            \"Cz\",\n        ],\n    ),\n    Preprocessor(\"resample\", sfreq=128),\n    Preprocessor(\"filter\", l_freq=1, h_freq=55),\n]\npreprocess(ds_eoec, preprocessors)\n\n# Extract 2-second segments\nwindows_ds = create_windows_from_events(\n    ds_eoec,\n    trial_start_offset_samples=0,\n    trial_stop_offset_samples=int(2 * ds_eoec.datasets[0].raw.info[\"sfreq\"]),\n    preload=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting a Single Channel for One Sample\n\nIt\u2019s always a good practice to verify that the data has been properly loaded\nand processed. Here, we plot a single channel from one sample to ensure the\nsignal is present and looks as expected.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(windows_ds[2][0][0, :].transpose())  # first channel of first epoch\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from eegdash import features\nfrom eegdash.features import extract_features\nfrom functools import partial\n\nsfreq = windows_ds.datasets[0].raw.info[\"sfreq\"]\nfilter_freqs = dict(windows_ds.datasets[0].raw_preproc_kwargs)[\"filter\"]\nfeatures_dict = {\n    \"sig\": features.FeatureExtractor(\n        {\n            \"mean\": features.signal_mean,\n            \"var\": features.signal_variance,\n            \"std\": features.signal_std,\n            \"skew\": features.signal_skewness,\n            \"kurt\": features.signal_kurtosis,\n            \"rms\": features.signal_root_mean_square,\n            \"ptp\": features.signal_peak_to_peak,\n            \"quan.1\": partial(features.signal_quantile, q=0.1),\n            \"quan.9\": partial(features.signal_quantile, q=0.9),\n            \"line_len\": features.signal_line_length,\n            \"zero_x\": features.signal_zero_crossings,\n        },\n    ),\n    \"spec\": features.SpectralFeatureExtractor(\n        {\n            \"rtot_power\": features.spectral_root_total_power,\n            \"band_power\": partial(\n                features.spectral_bands_power,\n                bands={\n                    \"theta\": (4.5, 8),\n                    \"alpha\": (8, 12),\n                    \"beta\": (12, 30),\n                },\n            ),\n            0: features.NormalizedSpectralFeatureExtractor(\n                {\n                    \"moment\": features.spectral_moment,\n                    \"entropy\": features.spectral_entropy,\n                    \"edge\": partial(features.spectral_edge, edge=0.9),\n                },\n            ),\n            1: features.DBSpectralFeatureExtractor(\n                {\n                    \"slope\": features.spectral_slope,\n                },\n            ),\n        },\n        fs=sfreq,\n        f_min=filter_freqs[\"l_freq\"],\n        f_max=filter_freqs[\"h_freq\"],\n        nperseg=2 * sfreq,\n        noverlap=int(1.5 * sfreq),\n    ),\n}\n\nfeatures_ds = extract_features(windows_ds, features_dict, batch_size=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features_ds.to_dataframe(include_crop_inds=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features_ds.fillna(0)\nfeatures_ds.zscore(eps=1e-7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "features_ds.to_dataframe(include_target=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating training and test sets\n\nThe code below creates a training and test set. We first split the data into\ntraining and test sets using the **train_test_split** function from the\n**sklearn** library. We then create a **TensorDataset** for the training and\ntest sets.\n\n1. **Set Random Seed** \u2013 The random seed is fixed using\n   `torch.manual_seed(random_state)` to ensure reproducibility in dataset\n   splitting and model training.\n2. **Extract Labels from the Dataset** \u2013 Labels (eye-open or eye-closed\n   events) are extracted from windows or features, stored as a NumPy array,\n   and printed for verification.\n3. **Split Dataset into Train and Test Sets** \u2013 The dataset is split into\n   training (80%) and testing (20%) subsets using `train_test_split()`,\n   ensuring balanced stratification based on the extracted labels.\n4. **Convert Data to PyTorch Tensors** \u2013 The selected training and testing\n   samples are converted into `FloatTensor` for input features and\n   `LongTensor` for labels, making them compatible with PyTorch models.\n5. **Create DataLoaders** \u2013 The datasets are wrapped in PyTorch DataLoader\n   objects with a batch size of 10, enabling efficient mini-batch training and\n   shuffling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\n\n# Set random seed for reproducibility\nrandom_state = 42\ntorch.manual_seed(random_state)\nnp.random.seed(random_state)\n\n# Extract labels from the dataset\neo_ec = np.array([ds[1] for ds in features_ds]).ravel()  # check labels\nprint(\"labels: \", eo_ec)\n\n# Get balanced indices for male and female subjects\ntrain_indices, test_indices = train_test_split(\n    range(len(features_ds)), test_size=0.2, stratify=eo_ec, random_state=random_state\n)\n\n# Convert the data to tensors\nX_train = torch.FloatTensor(\n    np.array([features_ds[i][0] for i in train_indices])\n)  # Convert list of arrays to single tensor\nX_test = torch.FloatTensor(\n    np.array([features_ds[i][0] for i in test_indices])\n)  # Convert list of arrays to single tensor\ny_train = torch.LongTensor(eo_ec[train_indices])  # Convert targets to tensor\ny_test = torch.LongTensor(eo_ec[test_indices])  # Convert targets to tensor\ndataset_train = TensorDataset(X_train, y_train)\ndataset_test = TensorDataset(X_test, y_test)\n\n# Create data loaders for training and testing (batch size 10)\ntrain_loader = DataLoader(dataset_train, batch_size=10, shuffle=True)\ntest_loader = DataLoader(dataset_test, batch_size=10, shuffle=True)\n\n# Print shapes and sizes to verify split\nprint(\n    f\"Shape of data {X_train.shape} number of samples - Train: {len(train_loader)}, Test: {len(test_loader)}\"\n)\nprint(\n    f\"Eyes-Open/Eyes-Closed balance, train: {np.mean(eo_ec[train_indices]):.2f}, test: {np.mean(eo_ec[test_indices]):.2f}\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check labels\n\nIt is good practice to verify the labels and ensure the random seed is\nfunctioning correctly. If all labels are 0s (eyes closed) or 1s (eyes open),\nit could indicate an issue with data loading or stratification, requiring\nfurther investigation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Visualize a batch of target labels\ndataiter = iter(train_loader)\nfirst_item, label = dataiter.__next__()\nlabel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create model\n\nThe model is a shallow convolutional neural network (ShallowFBCSPNet) with 24\ninput channels (EEG channels), 2 output classes (eyes-open and eyes-closed),\nand an input window size of 256 samples (2 seconds of EEG data).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch import nn\nfrom torchinfo import summary\n\ntorch.manual_seed(random_state)\n# MLP\nmodel = nn.Sequential(\n    nn.Flatten(),\n    nn.Linear(features_ds.datasets[0].n_features, 100),\n    nn.Linear(100, 100),\n    nn.Linear(100, 100),\n    nn.Linear(100, 2),\n)\n\nsummary(model, input_size=first_item.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training and Evaluation Process\n\nThis section trains the neural network using the Adamax optimizer, normalizes\ninput data, computes cross-entropy loss, updates model parameters, and tracks\naccuracy across six epochs.\n\n1. **Set Up Optimizer and Learning Rate Scheduler** \u2013 The `Adamax` optimizer\n   initializes with a learning rate of 0.002 and weight decay of 0.001 for\n   regularization. An `ExponentialLR` scheduler with a decay factor of 1 keeps\n   the learning rate constant.\n2. **Allocate Model to Device** \u2013 The model moves to the specified device\n   (CPU, GPU, or MPS for Mac silicon) to optimize computation efficiency.\n3. **Normalize Input Data** \u2013 The `normalize_data` function standardizes input\n   data by subtracting the mean and dividing by the standard deviation along\n   the time dimension before transferring it to the appropriate device.\n4. **Evaluates Classification Accuracy Over Six Epochs** \u2013 The training loop\n   iterates through data batches with the model in training mode. It\n   normalizes inputs, computes predictions, calculates cross-entropy loss,\n   performs backpropagation, updates model parameters, and steps the learning\n   rate scheduler. It tracks correct predictions to compute accuracy.\n5. **Evaluate on Test Data** \u2013 After each epoch, the model runs in evaluation\n   mode on the test set. It computes predictions on normalized data and\n   calculates test accuracy by comparing outputs with actual labels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.002, weight_decay=0.001)\nscheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1)\n\ndevice = torch.device(\"cpu\")\nmodel = model.to(device=device)  # move the model parameters to CPU/GPU\nepochs = 6\n\nfor e in range(epochs):\n    # training\n    correct_train = 0\n    for t, (x, y) in enumerate(train_loader):\n        model.train()  # put model to training mode\n        scores = model(x)\n        y = y.to(device=device, dtype=torch.long)\n        _, preds = scores.max(1)\n        correct_train += (preds == y).sum() / len(dataset_train)\n\n        loss = F.cross_entropy(scores, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n    # Validation\n    correct_test = 0\n    for t, (x, y) in enumerate(test_loader):\n        model.eval()  # put model to testing mode\n        scores = model(x)\n        y = y.to(device=device, dtype=torch.long)\n        _, preds = scores.max(1)\n        correct_test += (preds == y).sum() / len(dataset_test)\n\n    # Reporting\n    print(\n        f\"Epoch {e}, Train accuracy: {correct_train:.2f}, Test accuracy: {correct_test:.2f}\"\n    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n\ndata_df = features_ds.to_dataframe(include_target=True)\nX_train, y_train = (\n    data_df.drop(\"target\", axis=1).iloc[train_indices],\n    data_df.loc[train_indices, \"target\"],\n)\nX_val, y_val = (\n    data_df.drop(\"target\", axis=1).iloc[test_indices],\n    data_df.loc[test_indices, \"target\"],\n)\n\nclf = LGBMClassifier()\nclf.fit(X_train, y_train)\n\ny_hat_train = clf.predict(X_train)\ncorrect_train = (y_train == y_hat_train).mean()\ny_hat_val = clf.predict(X_val)\ncorrect_val = (y_val == y_hat_val).mean()\nprint(f\"Train accuracy: {correct_train:.2f}, Validation accuracy: {correct_val:.2f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from lightgbm import plot_importance\n\nplot_importance(clf, importance_type=\"split\", max_num_features=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_importance(clf, importance_type=\"gain\", max_num_features=10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}