{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working Offline with EEGDash\n\nMany HPC clusters restrict or block network access. It's common to have\ndedicated queues for internet-enabled jobs that differ from GPU queues.\nThis tutorial shows how to use :doc:`EEGChallengeDataset\n</api/dataset/eegdash.dataset.EEGChallengeDataset>` offline once a dataset is\npresent on disk.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport platformdirs\n\nfrom eegdash.const import RELEASE_TO_OPENNEURO_DATASET_MAP\nfrom eegdash.dataset.dataset import EEGChallengeDataset\n\n\n# We'll use Release R2 as an example (HBN subset).\n# :doc:`EEGChallengeDataset </api/dataset/eegdash.dataset.EEGChallengeDataset>`\n# uses a suffixed cache folder for the competition data (e.g., \"-bdf-mini\").\nrelease = \"R2\"\ndataset_id = RELEASE_TO_OPENNEURO_DATASET_MAP[release]\ntask = \"RestingState\"\n# Choose a cache directory. This should be on a fast local filesystem.\ncache_dir = Path(platformdirs.user_cache_dir(\"EEGDash\"))\ncache_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Populate the local cache (Online)\nThis block downloads the dataset from S3 to your local cache directory.\nRun this part on a machine with internet access. If the dataset is already\non your disk at the specified ``cache_dir``, you can comment out or skip\nthis section.\n\nTo keep this example self-contained, we prefetch the data here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_online = EEGChallengeDataset(\n    release=release,\n    cache_dir=cache_dir,\n    task=task,\n    mini=True,\n)\n\n# Optional prefetch of all recordings (downloads everything to cache).\nfrom joblib import Parallel, delayed\n\n_ = Parallel(n_jobs=-1)(delayed(lambda d: d.raw)(d) for d in ds_online.datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Basic Offline Usage\nOnce the data is cached locally, you can interact with it without needing an\ninternet connection. The key is to instantiate your dataset object with the\n``download=False`` flag. This tells :doc:`EEGChallengeDataset\n</api/dataset/eegdash.dataset.EEGChallengeDataset>`\nto look for data in the ``cache_dir`` instead of trying to connect to the\ndatabase or S3.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Here we check that the local cache folder exists\noffline_root = cache_dir / f\"{dataset_id}-bdf-mini\"\nprint(f\"Local dataset folder exists: {offline_root.exists()}\\n{offline_root}\")\n\nds_offline = EEGChallengeDataset(\n    release=release,\n    cache_dir=cache_dir,\n    task=task,\n    download=False,\n)\n\nprint(f\"Found {len(ds_offline.datasets)} recording(s) offline.\")\nif ds_offline.datasets:\n    print(\"First record bidspath:\", ds_offline.datasets[0].record[\"bidspath\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Filtering Entities Offline\nEven without a database connection, you can still filter your dataset by\nBIDS entities like subject, session, or task. When ``download=False``,\n:doc:`EEGChallengeDataset </api/dataset/eegdash.dataset.EEGChallengeDataset>`\nuses the BIDS directory structure and filenames to apply these filters. This\nexample shows how to load data for a specific subject from the local cache.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_offline_sub = EEGChallengeDataset(\n    cache_dir=cache_dir,\n    release=release,\n    download=False,\n    subject=\"NDARAB793GL3\",\n)\n\nprint(f\"Filtered by subject=NDARAB793GL3: {len(ds_offline_sub.datasets)} recording(s).\")\nif ds_offline_sub.datasets:\n    keys = (\"dataset\", \"subject\", \"task\", \"run\")\n    print(\"Records (dataset, subject, task, run):\")\n    for idx, base_ds in enumerate(ds_offline_sub.datasets, start=1):\n        rec = base_ds.record\n        summary = \", \".join(f\"{k}={rec.get(k)}\" for k in keys)\n        print(f\"  {idx:03d}: {summary}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Comparing Online vs. Offline Data\nAs a sanity check, you can verify that the data loaded from your local cache\nis identical to the data fetched from the online sources. This section\ncompares the shape of the raw data from the online and offline datasets to\nensure they match. This is a good way to confirm your local cache is complete\nand correct.\n\nIf you have network access, you can uncomment the block below to download and\ncompare shapes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw_online = ds_online.datasets[0].raw\nraw_offline = ds_offline.datasets[0].raw\nprint(\"online shape:\", raw_online.get_data().shape)\nprint(\"offline shape:\", raw_offline.get_data().shape)\nprint(\"shapes equal:\", raw_online.get_data().shape == raw_offline.get_data().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4.1: Comparing Descriptions, Online vs. Offline Data\n\nIf you have network access, you can uncomment the block below to download and\ncompare shapes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "description_online = ds_online.description\ndescription_offline = ds_offline.description\nprint(description_offline)\nprint(description_online)\nprint(\"Online description shape:\", description_online.shape)\nprint(\"Offline description shape:\", description_offline.shape)\nprint(\"Descriptions equal:\", description_online.equals(description_offline))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes and troubleshooting\n- Working offline selects recordings by parsing BIDS filenames and directory\n  structure. Some DB-only fields are unavailable; entity filters (subject,\n  session, task, run) usually suffice.\n- If you encounter issues, please open a GitHub issue so we can discuss.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}