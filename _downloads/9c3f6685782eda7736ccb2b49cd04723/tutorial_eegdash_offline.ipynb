{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab:\n# `pip install eegdash`\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Working Offline with EEGDash\n\nMany HPC clusters restrict or block network access. It's common to have\ndedicated queues for internet-enabled jobs that differ from GPU queues.\nThis tutorial shows how to use EEGDash offline once a dataset is present\non disk.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nimport platformdirs\n\nfrom eegdash.const import RELEASE_TO_OPENNEURO_DATASET_MAP\nfrom eegdash.dataset.dataset import EEGChallengeDataset\n\n\n# We'll use Release R2 as an example (HBN subset). EEGChallengeDataset uses a\n# suffixed cache folder for the competition data (e.g., \"-bdf-mini\").\nrelease = \"R2\"\ndataset_id = RELEASE_TO_OPENNEURO_DATASET_MAP[release]\ntask = \"RestingState\"\n# Choose a cache directory. This should be on a fast local filesystem.\ncache_dir = Path(platformdirs.user_cache_dir(\"EEGDash\"))\ncache_dir.mkdir(parents=True, exist_ok=True)\n\n# ######################################################################\n# Step 1: Populate the local cache (Online)\n# -----------------------------------------\n# This block downloads the dataset from S3 to your local cache directory.\n# Run this part on a machine with internet access. If the dataset is already\n# on your disk at the specified ``cache_dir``, you can comment out or skip\n# this section.\n#\n# To keep this example self-contained, we prefetch the data here.\n\nds_online = EEGChallengeDataset(\n    release=release,\n    cache_dir=cache_dir,\n    task=task,\n    mini=True,\n)\n\n# Optional prefetch of all recordings (downloads everything to cache).\nfrom joblib import Parallel, delayed\n\n_ = Parallel(n_jobs=-1)(delayed(lambda d: d.raw)(d) for d in ds_online.datasets)\n\n\n# ######################################################################\n# Step 2: Basic Offline Usage\n# ---------------------------\n# Once the data is cached locally, you can interact with it without needing an\n# internet connection. The key is to instantiate your dataset object with the\n# ``download=False`` flag. This tells EEGDash to look for data in the\n# ``cache_dir`` instead of trying to connect to the database or S3.\n\n\n# Here we check that the local cache folder exists\noffline_root = cache_dir / f\"{dataset_id}-bdf-mini\"\nprint(f\"Local dataset folder exists: {offline_root.exists()}\\n{offline_root}\")\n\nds_offline = EEGChallengeDataset(\n    release=release,\n    cache_dir=cache_dir,\n    task=task,\n    download=False,\n)\n\nprint(f\"Found {len(ds_offline.datasets)} recording(s) offline.\")\nif ds_offline.datasets:\n    print(\"First record bidspath:\", ds_offline.datasets[0].record[\"bidspath\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## %%\nStep 3: Filtering Entities Offline\n----------------------------------\nEven without a database connection, you can still filter your dataset by\nBIDS entities like subject, session, or task. When ``download=False``, EEGDash\nuses the BIDS directory structure and filenames to apply these filters. This\nexample shows how to load data for a specific subject from the local cache.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ds_offline_sub = EEGChallengeDataset(\n    cache_dir=cache_dir,\n    release=release,\n    download=False,\n    subject=\"NDARAB793GL3\",\n)\n\nprint(f\"Filtered by subject=NDARAB793GL3: {len(ds_offline_sub.datasets)} recording(s).\")\nif ds_offline_sub.datasets:\n    keys = (\"dataset\", \"subject\", \"task\", \"run\")\n    print(\"Records (dataset, subject, task, run):\")\n    for idx, base_ds in enumerate(ds_offline_sub.datasets, start=1):\n        rec = base_ds.record\n        summary = \", \".join(f\"{k}={rec.get(k)}\" for k in keys)\n        print(f\"  {idx:03d}: {summary}\")\n\n\n# ######################################################################\n# Step 4: Comparing Online vs. Offline Data\n# -----------------------------------------\n# As a sanity check, you can verify that the data loaded from your local cache\n# is identical to the data fetched from the online sources. This section\n# compares the shape of the raw data from the online and offline datasets to\n# ensure they match. This is a good way to confirm your local cache is complete\n# and correct.\n#\n# If you have network access, you can uncomment the block below to download and\n# compare shapes.\n\nraw_online = ds_online.datasets[0].raw\nraw_offline = ds_offline.datasets[0].raw\nprint(\"online shape:\", raw_online.get_data().shape)\nprint(\"offline shape:\", raw_offline.get_data().shape)\nprint(\"shapes equal:\", raw_online.get_data().shape == raw_offline.get_data().shape)\n\n# ######################################################################\n# Step 4.1: Comparing Descriptions, Online vs. Offline Data\n# ---------------------------------------------------------\n#\n# If you have network access, you can uncomment the block below to download and\n# compare shapes.\ndescription_online = ds_online.description\ndescription_offline = ds_offline.description\nprint(description_offline)\nprint(description_online)\nprint(\"Online description shape:\", description_online.shape)\nprint(\"Offline description shape:\", description_offline.shape)\nprint(\"Descriptions equal:\", description_online.equals(description_offline))\n\n# ######################################################################\n# Notes and troubleshooting\n# -------------------------\n# - Working offline selects recordings by parsing BIDS filenames and directory\n#   structure. Some DB-only fields are unavailable; entity filters (subject,\n#   session, task, run) usually suffice.\n# - If you encounter issues, please open a GitHub issue so we can discuss."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}